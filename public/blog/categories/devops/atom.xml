<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">

  <title><![CDATA[Category: DevOps | Charles Hooper]]></title>
  <link href="http://www.charleshooper.net/blog/categories/devops/atom.xml" rel="self"/>
  <link href="http://www.charleshooper.net/"/>
  <updated>2014-06-21T06:47:30-07:00</updated>
  <id>http://www.charleshooper.net/</id>
  <author>
    <name><![CDATA[Charles Hooper]]></name>
    
  </author>
  <generator uri="http://octopress.org/">Octopress</generator>

  
  <entry>
    <title type="html"><![CDATA[Troubleshooting ELBs with elbping]]></title>
    <link href="http://www.charleshooper.net/blog/troubleshooting-elbs-with-elbping/"/>
    <updated>2013-10-19T10:49:00-07:00</updated>
    <id>http://www.charleshooper.net/blog/troubleshooting-elbs-with-elbping</id>
    <content type="html"><![CDATA[<h1 id="section"></h1>

<p>Troubleshooting ELBs can be pretty painful at times because they are
largely a black box. There aren’t many metrics available, and the ones
that do exist are aggregated across all of the nodes of an ELB. This can
be troublesome at times, for example when only a subset of an ELB’s
nodes are degraded.</p>

<h1 id="elb-properties">ELB Properties</h1>

<p>ELBs have some interesting properties. For instance:</p>

<ul>
  <li>ELBs are made up of 1 or more nodes</li>
  <li>These nodes are published as A records for the ELB name</li>
  <li>These nodes can fail, or be shut down, and connections will <em>not</em> be closed gracefully</li>
  <li>It often requires a good relationship with Amazon support ($$$) to get someone to dig into ELB problems</li>
</ul>

<p><em>NOTE: Another interesting property but slightly less pertinent is that
ELBs were not designed to handle sudden spikes of traffic. They
typically require 15 minutes of heavy traffic before they will scale up
or they can be pre-warmed on request via a support ticket</em></p>

<h1 id="troubleshooting-elbs-manually">Troubleshooting ELBs (manually)</h1>

<p><strong>Update:</strong> <em>Since writing this blog post, AWS has since migrated all
ELBs to use Route 53 for DNS. In addition, all ELBs now have a
<code>all.$elb_name</code> record that will return the full list of nodes for the
ELB. For example, if your ELB name is
<code>elb-123456789.us-east-1.elb.amazonaws.com</code>, then you would get the full
list of nodes by doing something like <code>dig
all.elb-123456789.us-east-1.elb.amazonaws.com</code>. In addition, Route 53 is
able to return up to 4KB of data still using UDP, so using the <code>+tcp</code>
flag may not be necessary.</em></p>

<p>Knowing this, you can do a little bit of troubleshooting on your own.
First, resolve the ELB name to a list of nodes (as A records):</p>

<pre><code>$ dig @ns-942.amazon.com +tcp elb-123456789.us-east-1.elb.amazonaws.com ANY
</code></pre>

<p>The <code>tcp</code> flag is suggested as your ELB could have too many records to fit
inside of a single UDP packet. You also need to perform an <code>ANY</code> query because
Amazon’s nameservers will only return a subset of the nodes otherwise.  Running
this command will give you output that looks something like this (trimmed for
brevity):</p>

<pre><code>;; ANSWER SECTION:
elb-123456789.us-east-1.elb.amazonaws.com. 60 IN SOA ns-942.amazon.com. root.amazon.com. 1376719867 3600 900 7776000 60
elb-123456789.us-east-1.elb.amazonaws.com. 600 IN NS ns-942.amazon.com.
elb-123456789.us-east-1.elb.amazonaws.com. 60 IN A 54.243.63.96
elb-123456789.us-east-1.elb.amazonaws.com. 60 IN A 23.21.73.53
</code></pre>

<p>Now, for each of the <code>A</code> records use e.g. <code>curl</code> to test a connection to
the ELB. Of course, you also want to isolate your test to just the ELB
without connecting to your backends. One final property and little known
fact about ELBs:</p>

<ul>
  <li>The maximum size of the request method (verb) that can be sent through an ELB is <strong>127 characters</strong>. Any larger and the ELB will reply with an <em>HTTP 405 - Method not allowed</em>.</li>
</ul>

<p>This means that we can take advantage of this behavior to test only that
the ELB is responding:</p>

<pre><code>$ curl -X $(python -c 'print "A" * 128') -i http://ip.of.individual.node
HTTP/1.1 405 METHOD_NOT_ALLOWED
Content-Length: 0
Connection: Close
</code></pre>

<p>If you see <code>HTTP/1.1 405 METHOD_NOT_ALLOWED</code> then the ELB is responding
successfully. You might also want to adjust curl’s timeouts to values
that are acceptable to you.</p>

<h1 id="troubleshooting-elbs-using-elbping">Troubleshooting ELBs using elbping</h1>

<p>Of course, doing this can get pretty tedious so I’ve built a tool to
automate this called <a href="https://github.com/chooper/elbping">elbping</a>. It’s
available as a ruby gem, so if you have rubygems then you can install it
by simply doing:</p>

<pre><code>$ gem install elbping
</code></pre>

<p>Now you can run:</p>

<pre><code>$ elbping -c 4 http://elb-123456789.us-east-1.elb.amazonaws.com
Response from 54.243.63.96: code=405 time=210 ms
Response from 23.21.73.53: code=405 time=189 ms
Response from 54.243.63.96: code=405 time=191 ms
Response from 23.21.73.53: code=405 time=188 ms
Response from 54.243.63.96: code=405 time=190 ms
Response from 23.21.73.53: code=405 time=192 ms
Response from 54.243.63.96: code=405 time=187 ms
Response from 23.21.73.53: code=405 time=189 ms
--- 54.243.63.96 statistics ---
4 requests, 4 responses, 0% loss
min/avg/max = 187/163/210 ms
--- 23.21.73.53 statistics ---
4 requests, 4 responses, 0% loss
min/avg/max = 188/189/192 ms
--- total statistics ---
8 requests, 8 responses, 0% loss
min/avg/max = 188/189/192 ms
</code></pre>

<p>Remember, if you see <code>code=405</code> then that means that the ELB is responding.</p>

<h1 id="next-steps">Next Steps</h1>

<p>Whichever method you choose, you will at least know if your ELB’s nodes
are responding or not. Armed with this knowledge, you can either turn
your focus to troubleshooting other parts of your stack or be able to
make a pretty reasonable case to AWS that something is wrong.</p>

<p>Hope this helps!</p>

]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Intro to Operations: Metrics Collection]]></title>
    <link href="http://www.charleshooper.net/blog/intro-to-ops-metrics-collection/"/>
    <updated>2013-05-07T14:51:00-07:00</updated>
    <id>http://www.charleshooper.net/blog/intro-to-operations-metrics-collection</id>
    <content type="html"><![CDATA[<h1 id="section"></h1>

<p><em>I’m writing a series of blog posts for managers and other people
without an operations background in order to introduce certain best
practices regarding Operations. For the rest of the blog posts, please
visit the <a href="/blog/intro-to-ops-for-startups/">introductory Intro to Operations</a> blog post!</em></p>

<p>Collecting metrics is another area that many early stage startups seem
to overlook even though it is probably one of the most important things
they can do. By metrics collection, I am referring to the gathering and
storing of various metrics at several different levels. As John Allspaw
identifies them in <a href="http://www.amazon.com/Web-Operations-Keeping-Data-Time/dp/1449377440">Web Operations: Keeping the Data on Time</a>, they
are:</p>

<ul>
  <li><strong>High-level business and application metrics</strong> (e.g. user sign-ups)</li>
  <li><strong>Feature-specific application-level metrics</strong> (e.g. widgets processed)</li>
  <li>
    <p><strong>Systems and service-level metrics</strong> (e.g. server load or database queries per second)</p>

  </li>
</ul>

<p>You’ll note that there are two levels of “application-level” metrics.
The higher-level application metrics are mostly those that can be tied
to business objectives, while the other category of application metrics
are generally more feature specific.</p>

<p>Benefits incurred by collecting these metrics are plentiful. For one,
having quick access to these metrics is helpful during troubleshooting
and incident response. For example, I was once hired under contract to
look into why a certain company’s API was unreliable for the previous
few months. At least once per day, this company’s API would time out and
not respond to client requests. After enabling basic metrics collection
for the servers and services used by the API, it very quickly became
obvious that the database servers were reaching their connection limits
which was preventing the API from retrieving records from the database.
Not only was this problem identified very quickly, but later on we were
able to look back at our metrics data to assess how close to our limits
we were getting.</p>

<p>Another benefit is that you can integrate the metrics into your
<a href="/blog/intro-to-ops-availability-monitoring-alerting/">Availability monitoring</a> system to be alerted when metrics surpass
some threshold or change significantly. Not only that, but analyzing
these metrics will allow you to manage your capacity intelligently and
build a business case to justify infrastructure expenditures. Finally,
analyzing these metrics will also give you insight into your
application, how it’s used, and your business.</p>

<p>How you go about collecting and storing these metrics is up to you. Many
engineers might be tempted to build their own solution; however, there
are many open source and third party software packages that you may find
helpful. Key considerations when choosing which package or packages to
use are:</p>

<ul>
  <li>The ability to add new, custom metrics</li>
  <li>Configurable resolution/storage trade-off</li>
  <li>Integration with availability monitoring and alerting systems</li>
  <li>Graphing/visualization</li>
</ul>

<p>If your startup doesn’t have any metrics then you should start
collecting them now. The visualization will help you in the short run
and the historical data will help you in the long run.</p>

]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Intro to Operations: Availability Monitoring and Alerting]]></title>
    <link href="http://www.charleshooper.net/blog/intro-to-ops-availability-monitoring-alerting/"/>
    <updated>2013-05-05T21:57:00-07:00</updated>
    <id>http://www.charleshooper.net/blog/intro-to-operations-availability-monitoring-and-alerting</id>
    <content type="html"><![CDATA[<h1 id="section"></h1>

<p><em>I’m writing a series of blog posts for managers and other people
without an operations background in order to introduce certain best
practices regarding Operations. For the rest of the blog posts, please
visit the <a href="/blog/intro-to-ops-for-startups/">introductory Intro to Operations</a> blog post!</em></p>

<p>Another area I’ve seen alot of early stage startups lacking in is
<strong>availability monitoring and alerting</strong>. The essence of availability
monitoring and alerting is being notified when your service is not
working as expected, including when it’s simply down, isn’t meeting
formal or informal SLAs (e.g., it’s too slow), or certain functionality
is broken.</p>

<p>What I typically see is that some effort was made to set up this type of
monitoring before and never maintained. Symptoms include <em>poor
monitoring coverage</em> (<em>servers missing from the config, services
monitoring nearly non-existent</em>), <em>large amounts of false positives and
negatives</em>, <em>inactionable alerts</em>, and <em>alerts that go unignored</em>
because of the previous issues.</p>

<p>Symptoms on the business include not knowing when your service is down
and finding out that your service is broken <em>from your customers</em>.
Finding out that your service is down from your customers is not only
embarrassing but it also shakes their confidence in you, affects your
reputation, and may even lead to lost revenue.</p>

<p>The good news is that it doesn’t have to be this way. When availability
monitoring is set up properly, maintained, and you and your employees
agree to approach alerts a specific way, you will be able to reap a
variety of benefits. Here’s what I recommend:</p>

<ol>
  <li>
    <p>First, collaborate with your employees to define who is in the pager
  rotation and the escalation policies. Ask yourself: What happens when
  the on call engineer is overwhelmed and needs backup? What happens when
  the engineer goes on vacation?</p>
  </li>
  <li>
    <p>Next, take inventory of what services you rely on and define an
  internal SLA for them. This does not have to be a super formal process,
  but this inventory and SLA will be helpful for deciding what thresholds
  to set in your monitoring to avoid false positives. Try to see the big
  picture and think about everything such as:</p>

    <ul>
      <li>Servers,</li>
      <li>Self-managed supporting services like web servers, databases, email services,</li>
      <li>Application functionality and features - one strategy I like is exposing a “health check” service that can be checked by the monitoring agent,</li>
      <li>Third party services like remote APIs.</li>
    </ul>
  </li>
</ol>

<p>Your inventory and SLA definition is a living document; remember to
  keep it up to date!</p>

<ol>
  <li>Then set up whatever monitoring package you or your engineers decided
  to use (self-hosted or third party) such as <a href="http://www.nagios.org/">nagios</a>, <a href="http://www.zenoss.com/">Zenoss</a>,
  <a href="http://www.pingdom.com/">Pingdom</a>, or <a href="http://www.copperegg.com/">CopperEgg</a> and have your monitoring configured for
  those services. If you’re really good, you’ll <em>check your configuration
  into its own source control repository</em>. If you go the self-hosted
  route, it may also be worth having your monitoring server monitored
  externally.  Who’s watching the watcher indeed. </li>
</ol>

<ol>
  <li>Think about integrating your monitoring with a pager service such as
  <a href="http://www.pagerduty.com/">PagerDuty</a>. Services like PagerDuty allow you to input your pager
  rotation and then define good rules for how to contact the on call
  engineer and when to escalate should the engineer be unavailable.</li>
</ol>

<ol>
  <li>
    <p>With improved monitoring and alerting in place, you may want to think
  about giving certain customers “911” access. At a previous company I
  worked at, we had a secret email address our big customers could hit
  which would <em>open a support ticket</em> and then <em>page the on call engineer</em>
  with the ticket number. If you decide to go this route; however, you’ll
  want to <em>train your customers</em> when it’s appropriate to use this power
  and how to use it most effectively.</p>
  </li>
  <li>
    <p>Adjust alerts and fix problems as you get paged for them. Don’t care
  that a particular API goes down during a known maintenance window?
  Schedule the notification policy accordingly.</p>
  </li>
  <li>
    <p>Finally, continue maintaining your inventory and monitoring
  service’s configuration. For extra benefit, consider tracking your
  organization’s <strong>Mean Time To Respond</strong> (how long it took for engineer to
  acknowledge that something is wrong) and your <strong>Mean Time To Recover</strong>
  (how long it took the engineer to resolve the issue <em>including</em> the Mean
  Time To Respond), your <strong>Mean Time Between Failures</strong> (self-explanatory,
  I hope), and <strong>Percent Availability</strong> (what percent of time your service
  is functional in a given period of time). </p>
  </li>
</ol>

<p>This concludes the management and non-ops introduction to operations; I
hope you find this helpful.</p>

]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Intro to Operations: Configuration Management]]></title>
    <link href="http://www.charleshooper.net/blog/intro-to-ops-config-management/"/>
    <updated>2013-05-05T20:12:00-07:00</updated>
    <id>http://www.charleshooper.net/blog/intro-to-operations-configuration-management</id>
    <content type="html"><![CDATA[<h1 id="section"></h1>

<p><em>I’m writing a series of blog posts for managers and other people
without an operations background in order to introduce certain best
practices regarding Operations. For the rest of the blog posts, please
visit the <a href="/blog/intro-to-ops-for-startups/">introductory Intro to Operations</a> blog post!</em></p>

<p>One of the areas I’ve witnessed early stage startups lacking in is
<strong>configuration management</strong>. <em>Configuration management is the process of
standardizing and enforcing configurations</em>. In other words,
configuration management is about deciding on a specific configuration
of services for various roles and then applying these configurations in
practice. Typically, these manifests are written in (domain-specific)
language and is specific to the <em>configuration management software</em>
being used, such as <a href="https://puppetlabs.com/">puppet</a>, <a href="http://www.opscode.com/chef/">chef</a>, <a href="http://cfengine.com/">cfengine</a>, or
<a href="http://saltstack.com/community.html">salt stack</a>.</p>

<p>There are many benefits to configuration management. For one,
configuration management allows developers to spend more time working on
the product and less time deploying new services. This is because
configuration is now automated and faster as a result. In addition,
environments are standardized and therefore less time is spent
troubleshooting or diagnosing edge cases in different environments.
Finally, when coupled with <em>source control management</em>, the proper use
of configuration management can be used to track and audit what has
changed over time and who changed it.</p>

<p>In many of these early stage startups, there is either very little
configuration management performed at all, or configuration management
exists as a series of shell scripts cobbled together to do some
post-hardware setup. If you’re lucky, there exists a document somewhere
that describes when and how to run these scripts to deploy new services.</p>

<p>The way configuration management works is that engineers create a
collection of files that define how the system should be configured.
This collection of files is typically called a <strong>manifest</strong>. Then, once
physical or virtual hardware has been provisioned, one of these
manifests is <em>applied</em> to the new host. During application, the
configuration management software will interpret the new configuration,
install software packages, manage users and credentials, alter config
files, manage file permissions, run arbitrary commands, and so on. Once
the manifest is fully applied, the new host should be fully configured
and ready to be used!  In some environments; however, they may be a
post-host-provisioning step where additional work is performed
afterwards, such as checking out application code from a source control
repository.</p>

<p>If you’re not using configuration management already then you should
start now because, frankly, it’s never too early. Starting configuration
management now will not only help your first hired ops/systems engineer
from working backwards to write these manifests later, but will also
incur benefits (such as your developers spending less time away from
shipping value-added code) that will outweigh the initial learning
curve.</p>

]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Intro to Operations for Early Stage Startups]]></title>
    <link href="http://www.charleshooper.net/blog/intro-to-ops-for-startups/"/>
    <updated>2013-05-04T21:37:00-07:00</updated>
    <id>http://www.charleshooper.net/blog/intro-to-operations-for-early-stage-startups</id>
    <content type="html"><![CDATA[<h1 id="section"></h1>

<p>I’ve spent the last few years in a variety of roles for early stage tech
startups. While in these roles, I’ve noticed a pattern: <em>Early stage
startups don’t give much thought to their operations. In particular,
they typically don’t hire anyone specifically for that role because they
are focused on building their product.</em> In other words, all of their
technical hires are for developers.</p>

<p>What tends to happen in my experience is that <em>their developers soon
become overwhelmed</em> (especially after a growth spurt) and are unable to
spend their time shipping code that’s going to improve their product or
make their company money. Eventually, if they’re lucky, management catches
onto this and hires their first <strong>systems or operations engineer</strong>.</p>

<p>Because I’ve had the opportunity to be first-hired systems engineer,
what I’ve experienced is the effect of “working backwards” to undo a
bunch of things that weren’t done following best practices while
simultaneously moving things forward to improve them.</p>

<p>I decided to try to educate whoever would be willing to read this
(hopefully early stage startups!) about some <em>best practices</em> that will
not only save their future operations engineers some headache, but will
also improve their business. Part of this education will happen in the
form of one-on-one time with these startups. For example, I spent the
last couple of days sitting in on office hours at a startup accelerator.
The other part; however, will take place by writing “Intro to…”
articles and publishing them to a variety of places, including this blog.</p>

<p>Specifically, the topics I’ve chosen to write about are:</p>

<ul>
  <li><a href="/blog/intro-to-ops-config-management/">Configuration management</a></li>
  <li><a href="/blog/intro-to-ops-availability-monitoring-alerting/">Availability monitoring</a></li>
  <li>
    <p><a href="/blog/intro-to-ops-metrics-collection/">Metrics collection</a></p>

  </li>
</ul>

<p>Over the next week or so, I’ll write about each one of these topics and
post them to this blog. I hope people find them helpful!</p>

]]></content>
  </entry>
  
</feed>
