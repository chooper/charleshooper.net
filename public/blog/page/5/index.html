
<!DOCTYPE html>
<!--[if IEMobile 7 ]><html class="no-js iem7"><![endif]-->
<!--[if lt IE 9]><html class="no-js lte-ie8"><![endif]-->
<!--[if (gt IE 8)|(gt IEMobile 7)|!(IEMobile)|!(IE)]><!--><html class="no-js" lang="en"><!--<![endif]-->
<head>
  <meta charset="utf-8">
  <title>Charles Hooper</title>
  <meta name="author" content="Charles Hooper">

  
  <meta name="description" content="© uair01; some rights reserved. As a result of my now defunct project, BookSuggest, I’ve built a fairly large corpus that has been seeded entirely &hellip;">
  

  <!-- http://t.co/dKP3o1e -->
  <meta name="HandheldFriendly" content="True">
  <meta name="MobileOptimized" content="320">
  <meta name="viewport" content="width=device-width, initial-scale=1">

  
  <link rel="canonical" href="http://www.charleshooper.net/blog/page/5">
  <link href="/favicon.png" rel="icon">
  <link href="/stylesheets/screen.css" media="screen, projection" rel="stylesheet" type="text/css">
  <link href="http://feeds.feedburner.com/subversity" rel="alternate" title="Charles Hooper" type="application/atom+xml">
  <script src="/javascripts/modernizr-2.0.js"></script>
  <script src="//ajax.googleapis.com/ajax/libs/jquery/1.9.1/jquery.min.js"></script>
  <script>!window.jQuery && document.write(unescape('%3Cscript src="./javascripts/lib/jquery.min.js"%3E%3C/script%3E'))</script>
  <script src="/javascripts/octopress.js" type="text/javascript"></script>
  <!--Fonts from Google"s Web font directory at http://google.com/webfonts -->
<link href="http://fonts.googleapis.com/css?family=PT+Serif:regular,italic,bold,bolditalic" rel="stylesheet" type="text/css">
<link href="http://fonts.googleapis.com/css?family=PT+Sans:regular,italic,bold,bolditalic" rel="stylesheet" type="text/css">

  
  <script type="text/javascript">
    var _gaq = _gaq || [];
    _gaq.push(['_setAccount', 'UA-12888528-1']);
    _gaq.push(['_trackPageview']);

    setTimeout("_gaq.push(['_trackEvent', '60_seconds', 'read'])", 60000);

    (function() {
      var ga = document.createElement('script'); ga.type = 'text/javascript'; ga.async = true;
      ga.src = ('https:' == document.location.protocol ? 'https://ssl' : 'http://www') + '.google-analytics.com/ga.js';
      var s = document.getElementsByTagName('script')[0]; s.parentNode.insertBefore(ga, s);
    })();
  </script>



</head>

<body   >
  <header role="banner"><hgroup>
  <h1><a href="/">Charles Hooper</a></h1>
  
    <h2>Thoughts and projects from a Hacker and Engineering Manager</h2>
  
</hgroup>

</header>
  <nav role="navigation"><ul class="subscription" data-subscription="rss">
  <li><a href="http://feeds.feedburner.com/subversity" rel="subscribe-rss" title="subscribe via RSS">RSS</a></li>
  
</ul>
  
<form action="http://google.com/search" method="get">
  <fieldset role="search">
    <input type="hidden" name="q" value="site:www.charleshooper.net" />
    <input class="search" type="text" name="q" results="0" placeholder="Search"/>
  </fieldset>
</form>
  
<ul class="main-navigation">
  <li><a href="/">Blog</a></li>
	<li><a href="/about/">About Charles</a></li>
	<li><a href="/projects/">Projects</a></li>
	<li><a href="/contact/">Contact</a></li>
  <li><a href="/blog/archives">Archives</a></li>
</ul>

</nav>
  <div id="main">
    <div id="content">
      <div class="blog-index">
  
  
  
    <article>
      
  <header>
    
      <h1 class="entry-title"><a href="/blog/twitter-vs-erotica-your-corporas-source-matters/">Twitter vs Erotica: Your Corpora&#8217;s Source Matters</a></h1>
    
    
      <p class="meta">
        








  


<time datetime="2010-10-30T00:00:00-07:00" pubdate data-updated="true">Oct 30<span>th</span>, 2010</time>
        
      </p>
    
  </header>


  <div class="entry-content"><h1 id="section"></h1>

<p><img src="http://www.charleshooper.net/wp-content/uploads/3998147057_f5dd7ce442-150x150.jpg" alt="Dictionary" title="Dictionary" />
© uair01; some rights reserved.</p>

<p>As a result of my now <a href="http://www.charleshooper.net/blog/rip-booksuggest/">defunct project, BookSuggest</a>, I’ve built a fairly large corpus that has been seeded entirely from Twitter. This corpus weighs in at:</p>

<ul>
  <li>16,680,000 documents (tweets)</li>
  <li>1,970,165 unique (stemmed) words<br />
<em>(Red flag: <a href="http://www.oxforddictionaries.com/page/93">Oxford Dictionary</a> suggests there’s an estimated 250,000 words in the English language. This discrepancy is the result of my failure to filter Tweets based on language, the fact that usernames were included in the count, and the fact that people “make words up.” Also, “haha” becomes one word while “hahahaha” becomes another.)</em></li>
  <li>83,758,872 words total.</li>
</ul>

<p>When I look at these numbers, I often think about how the source documents a corpus/histogram is derived from affects the distribution of its term frequencies. The most obvious example is language. A French corpus will never come close to an English corpus. A less obvious example is subject matter. For example, a corpus derived from English literature will have a different term distribution than a corpus derived from an English medical journal. Common terms will have similar frequencies, but there will be biases towards terms that are domain-specific.</p>

<p>To demonstrate, I scraped the “Erotica” section of <a href="http://www.textfiles.com/">textfiles.com</a> and built a corpus based on the data there. The resulting corpus is composed of:</p>

<ul>
  <li>4,337 documents</li>
  <li>50,709 unique (stemmed) words</li>
  <li>10,413,715 words total.</li>
</ul>

<h2 id="notes-on-term-counting">Notes on Term Counting</h2>

<ul>
  <li>Words that had a length of <em>less than 4 characters</em> were <strong>discarded</strong></li>
  <li>Words were then <em>stemmed</em> using the <a href="http://tartarus.org/~martin/PorterStemmer/">Porter Stemming algorithm</a></li>
  <li>There may be some slight differences between how words were counted in both corpora, based on minor programming differences</li>
</ul>

<h2 id="the-data">The Data</h2>

<p>Finally, here are the term frequencies with the obvious domain-specific terms in bold:</p>

<p><strong>Corpus Seeded from Twitter</strong></p>

<p>![Counts of Top 20 Terms from Twitter Corpus][6]  </p>

<ol>
  <li>that (0.84%)</li>
  <li>just (0.70%)</li>
  <li>with (0.69%)</li>
  <li>thi (0.68%)</li>
  <li>have (0.65%)</li>
  <li>your (0.61%)</li>
  <li>like (0.56%)</li>
  <li>love (0.54%)</li>
  <li><strong>follow (0.45%)</strong></li>
  <li>what (0.44%)</li>
  <li>from (0.36%)</li>
  <li>haha (0.35%)</li>
  <li>good (0.34%)</li>
  <li>para (0.34%)</li>
  <li>will (0.32%)</li>
  <li>when (0.30%)</li>
  <li>know (0.30%)</li>
  <li>want (0.30%)</li>
  <li>about 0.30%)</li>
  <li>make (0.30%)</li>
</ol>

<p><strong>Corpus Seeded from Erotica</strong></p>

<p>![Counts of Top 20 Terms from Erotica Corpus][7]  </p>

<ol>
  <li>that (1.83%)</li>
  <li>with (1.42%)</li>
  <li>into (0.76%)</li>
  <li>down (0.70%)</li>
  <li>then (0.66%)</li>
  <li>back (0.66%)</li>
  <li>from (0.65%)</li>
  <li>thi (0.65%)</li>
  <li>hand (0.64%)</li>
  <li>were (0.59%)</li>
  <li>look (0.58%)</li>
  <li>have (0.58%)</li>
  <li><strong>cock (0.57%)</strong></li>
  <li>like (0.57%)</li>
  <li>over (0.57%)</li>
  <li>thei (0.56%)</li>
  <li>your (0.56%)</li>
  <li>what (0.55%)</li>
  <li>said (0.55%)</li>
  <li>could (0.54%)</li>
</ol>

<p>You’ll note that the Twitter corpus had a heavy bias towards the term “<em>follow</em>” whereas the Erotica corpus shows an overwhelming use of the term “<em>cock</em>” (Writers: Use synonyms.)</p>

<table>
  <tbody>
    <tr>
      <td>[6]: http://chart.apis.google.com/chart?chxl=0:</td>
      <td>that</td>
      <td>just</td>
      <td>with</td>
      <td>thi</td>
      <td>have</td>
      <td>your</td>
      <td>like</td>
      <td>love</td>
      <td>follow</td>
      <td>what</td>
      <td>from</td>
      <td>haha</td>
      <td>good</td>
      <td>para</td>
      <td>will</td>
      <td>when</td>
      <td>know</td>
      <td>want</td>
      <td>about</td>
      <td>make&amp;chxr=0,0,703297&amp;chxt=x&amp;chbh=a,4,10&amp;chs=600x200&amp;cht=bvg&amp;chco=4D89F9&amp;chds=0,703297&amp;chd=t:703297,582988,581346,573197,547218,513823,467673,455264,378187,367112,302254,296974,286671,283887,272176,254419,252303,251673,251325,248572&amp;chtt=Counts of Top 20 Terms from Twitter Corpus</td>
    </tr>
    <tr>
      <td>[7]: http://chart.apis.google.com/chart?chxl=0:</td>
      <td>that</td>
      <td>with</td>
      <td>into</td>
      <td>down</td>
      <td>then</td>
      <td>back</td>
      <td>from</td>
      <td>thi</td>
      <td>hand</td>
      <td>were</td>
      <td>look</td>
      <td>have</td>
      <td>cock</td>
      <td>like</td>
      <td>over</td>
      <td>thei</td>
      <td>your</td>
      <td>what</td>
      <td>said</td>
      <td>could&amp;chxr=0,0,190543&amp;chxt=x&amp;chbh=a,4,10&amp;chs=600x200&amp;cht=bvg&amp;chco=F889F9&amp;chds=0,190543&amp;chd=t:190543,148204,78688,72452,69045,68642,68164,67998,66826,61787,60236,60179,59622,59357,58856,58760,57851,57670,57348,55739&amp;chtt=Counts of Top 20 Terms from Erotica Corpus</td>
    </tr>
  </tbody>
</table>

<h2 id="practical-reasons-why-this-is-important">Practical Reasons Why This Is Important</h2>

<p>This is important because if I were to build a domain-specific search-engine, I would be better off  seeding my corpus from domain-specific content. If I don’t, my relevance (tf-idf) scores will be inaccurate. For example, an Erotica-specific search engine should decrease the weight for the term “<em>cock</em>” strictly because it has a very high document frequency and is therefore less-significant. Meanwhile, a Twitter-specific search engine should discount the weight of “<em>follow</em>.”</p>

<h2 id="conclusion">Conclusion</h2>

<p>To conclude, the subject matter of a document set will create a bias towards domain-specific terms in the document set’s histogram of term frequencies. If you are calculating relevance for any particular document set, you should use a corpus derived from that document set. In other words, if you can, try not to re-use your corpora!</p>

</div>
  
  


    </article>
  
  
    <article>
      
  <header>
    
      <h1 class="entry-title"><a href="/blog/wordpress-auto-upgrade-and-dumb-permissions/">WordPress Auto Upgrade and &#8220;Dumb&#8221; Permissions</a></h1>
    
    
      <p class="meta">
        








  


<time datetime="2010-10-29T00:00:00-07:00" pubdate data-updated="true">Oct 29<span>th</span>, 2010</time>
        
      </p>
    
  </header>


  <div class="entry-content"><h1 id="section"></h1>

<p>One of the nice features about WordPress is its ability to upgrade and
install plugins on the fly. This is nice because now you don’t need to
be bothered with the hassle of downloading plugins, unzipping their
contents, and transferring them to your web server.</p>

<p>Unfortunately, the way in which WordPress determines if it has the
appropriate permissions to upgrade plugins is implemented poorly. When
WordPress doesn’t think it has permission, the admin panel will instead
<strong>prompt you for FTP login information</strong>. This is a problem because
sometimes WordPress will do this falsely even if it <em>does</em> have proper
permissions.</p>

<h2 id="the-problem">The Problem</h2>

<p>The way WordPress tries to guess if it has proper permissions is very
primitive. Instead of using PHP’s <a href="http://us.php.net/manual/en/function.is-writable.php">is_writable</a>, WordPress instead
compares the web server’s User ID with the User ID of the wp-content
directory’s owner*. While this might work for a large number of cases,
it doesn’t work in all of them (including mine).</p>

<p>* It’s actually slightly more complicated than this, but the effect is the same.</p>

<h2 id="the-environment">The Environment</h2>

<p>I run WordPress 3.x on Ubuntu 10.04 LTS under Lighttpd and PHP5-cgi.
Lighttpd runs as user <code>www-data</code> and group <code>www-data</code>. If I wanted to
let WordPress’ auto-detection of permissions work, I would have to
change the owner of my website directories to www-data. This doesn’t fly
with me, because I also want my user to have easy access to my document
root and don’t like the idea of my data being user-owned by my webserver
user.</p>

<h2 id="the-solution">The Solution</h2>

<p>Instead of bending over to WordPress’ permission issues, I was able to
perform the following simple steps to have auto-installing/updating
plugins and themes *without *changing user ownership of my web files.</p>

<ol>
  <li>
    <p><code>sudo chgrp -R www-data /path/to/wp/wp-content</code></p>

    <p>This changes group ownership of wp-content and all sub-directories
to be group-owned by your webserver user. wp-content is where WordPress
stores plugins, themes, cache files, and (AFAIK) file uploads. </p>
  </li>
  <li>
    <p><code>sudo chmod -R g+w /path/to/wp/wp-content</code></p>

    <p>This makes wp-content and all of its sub-directories group-writable. </p>
  </li>
  <li>
    <p><code>sudo chmod g+s /path/to/wp/wp-content</code></p>

    <p>This, <code>g+s,</code> is known as <strong>setgid</strong>. This causes newly-created files
to be group-owned by <code>wp-content</code>’s owning group, in this case <code>www-data</code>. </p>
  </li>
  <li>
    <p>Finally, add the following to the bottom of <code>wp-config.php</code>. This is
an override built into the WordPress code. For more information, take a
look at <code>wp-admin/includes/file.php</code>’s function
<code>get_filesystem_method</code>. </p>
  </li>
</ol>

<div class="bogus-wrapper"><notextile><figure class="code"><figcaption><span>Enable direct file updating in wp-config.php </span></figcaption>
 <div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class="line-number">1</span>
<span class="line-number">2</span>
<span class="line-number">3</span>
<span class="line-number">4</span>
</pre></td><td class="code"><pre><code class="php"><span class="line"><span class="x">/* Force direct file updating</span>
</span><span class="line"><span class="x">- http://www.charleshooper.net/blog/wordpress-auto-upgrade-and-dumb-permissions/</span>
</span><span class="line"><span class="x">*/</span>
</span><span class="line"><span class="x">define(&#39;FS_METHOD&#39;, &#39;direct&#39;);</span>
</span></code></pre></td></tr></table></div></figure></notextile></div>

<p>So there you have it. WordPress does a poor job of properly detecting file permissions and, in some cases, needs to be overridden. If you’re still having problems after this, <strong>let me know</strong> and I will do my best to help you.</p>

</div>
  
  


    </article>
  
  
    <article>
      
  <header>
    
      <h1 class="entry-title"><a href="/blog/rip-booksuggest/">RIP BookSuggest</a></h1>
    
    
      <p class="meta">
        








  


<time datetime="2010-10-26T00:00:00-07:00" pubdate data-updated="true">Oct 26<span>th</span>, 2010</time>
        
      </p>
    
  </header>


  <div class="entry-content"><h1 id="section"></h1>

<p>BookSuggest, the web-based book recommendation engine, is officially dead. I’ve been treating BookSuggest as the lowest of priorities for quite some time now and I’m more than happy to declare this project a failure. Here is a brief recap of BookSuggest’s history.</p>

<p>Before BookSuggest was a web application, I used to <a href="http://www.charleshooper.net/blog/how-i-made-money-spamming-twitter-with-contextual-book-suggestions/">spam unsuspecting Twitter users</a> with book recommendations. Eventually, Twitter stepped up their anti-spam stance and suspended my spam account. I retired the project for a while until one day I decided to build a web application around the recommendation technology I was using.</p>

<p>This technology was simply scoring words in a user’s timeline, taking the four highest-scoring words, and then passing them to an Amazon ItemSearch query. More specifically, the type of search in use was what Amazon calls a TextStream search. This search method is what allowed me to get book recommendations, even if the search terms provided weren’t all that great. Without it, it’s not unlikely that my ItemSearches wouldn’t return any results at all.</p>

<p>So imagine my surprise when I read the following in Amazon’s API documentation:</p>

<blockquote>
  <p>Due to low usage, the Product Advertising API operations and response groups listed below will not be supported after October 15, 2010:</p>

  <p>…<br />
Additionally, due to low usage, we will be discontinuing Multiple Operation Requests and the <strong>TextStream</strong> search parameter.</p>
</blockquote>

<p>Oh, shoot!</p>

<p>Financially, it makes sense for me to cut my losses here. Back when I was still spamming Twitter, I was pulling over $100/mo. Through the web-app, my referral fees are much smaller. As of this moment, I have a balance of just $9 with Amazon and haven’t cashed out since the start of the project.</p>

<p>Some numbers:</p>

<ul>
  <li>Unique Twitter users: 393</li>
  <li>Recommendations made: 611</li>
  <li>Documents in corpus: 17,458,549</li>
  <li>Unique words in corpus: 1,970,165</li>
  <li>Top 5 words in corpus: that, just, with, this, have</li>
</ul>

<p>RIP BookSuggest!</p>
</div>
  
  


    </article>
  
  
    <article>
      
  <header>
    
      <h1 class="entry-title"><a href="/blog/code-responsibly/">Code Responsibly: What&#8217;s Best for Your Clients?</a></h1>
    
    
      <p class="meta">
        








  


<time datetime="2010-10-23T00:00:00-07:00" pubdate data-updated="true">Oct 23<span>rd</span>, 2010</time>
        
      </p>
    
  </header>


  <div class="entry-content"><h1 id="section"></h1>

<p>We programmers have a natural affinity for writing and using our own code. You can’t really blame us; this is akin to gardeners who prefer to eat vegetables they grow, or brewers who prefer to drink their own beer. However, this oftentimes leads to a frequent re-invention of the wheel. While this isn’t always a bad thing, it doesn’t usually benefit our clients and here’s why:</p>

<ol>
  <li>**Increased development time. **If a client is paying you hourly, why should they pay for you to re-invent a solution that already exists? Why write a new CMS if WordPress will do? When you write a new CMS from scratch for a client, you are increasing their development costs.</li>
  <li>**Freedom in hosting. **It’s no coincidence that many web developers also host their projects as well. This is fine for larger applications, but for the majority of the client work out there your clients should have the freedom to a broad range of hosting options. Vendor lock-in is a terrible thing.</li>
  <li>**Post-development support. **If a client needs customizations done to the code base, they should be able to solicit the work from almost any developer. Certainly you would want preference in these solicitations, but there shouldn’t be any clients who are stuck with you. When you use your own custom solution, you are increasing your clients’ maintenance costs.</li>
</ol>

<p>I’m <em>not</em> saying that you shouldn’t ever write new code. What I <em>am</em> saying is that your responsibility to the client is to use the best tools for the job and to put together the best solution for them that you can. Sometimes this means flexing your coding muscles and sometimes this means humbly setting up existing software such as WordPress. So please, write new code conservatively and responsibly.</p>
</div>
  
  


    </article>
  
  
    <article>
      
  <header>
    
      <h1 class="entry-title"><a href="/blog/validating-data-with-new-style-classes-in-python/">Validating Data With New-Style Classes in Python</a></h1>
    
    
      <p class="meta">
        








  


<time datetime="2010-10-11T00:00:00-07:00" pubdate data-updated="true">Oct 11<span>th</span>, 2010</time>
        
      </p>
    
  </header>


  <div class="entry-content"><h1 id="section"></h1>

<p>Every once in awhile in my reading I come across a minor reference to what pythonistas refer to as <strong>new-style classes</strong>. One of the nice things about new-style classes is the `property` decorators. These property decorators allow you to build getter and setter methods to access object attributes. This is pretty awesome because now you can perform validation at the model/class level whenever you assign a value to a property of an object.</p>

<p>e.g., In one of my projects, I have an attribute named <em>timestamp</em> that takes a `datetime` object. I was concerned about receiving incorrect types from my input because there are alot of ways a programmer can represent the concept of time. Some realistic possibilities of invalid types in my case are:</p>

<ul>
  <li>`time` objects from the time module</li>
  <li>`string` objects that contain the date and time (and various possible formats)</li>
  <li>`float` or `int` objects that contain a unix timestamp</li>
</ul>

<p>With a setter method, you can test that the new value being assigned to an attribute is the correct type before assigning it. You can also throw an <strong>exception</strong> if it’s not. In other words, you can do something like this:</p>

<pre><code>from datetime import datetime

class SomeObject(object):    # new-style classes must be subclassed from object
    _timestamp = None

    @property
    def timestamp(self):
        return self._timestamp

    @timestamp.setter    # the prefix must match the read-only getter func name
    def timestamp(self,value):    # the func name must match the read-only getter func name
        if not isinstance(value, datetime):
            raise ValueError(“Timestamp can only be an instance of Datetime”)
        self._timestamp = value
</code></pre>

<p>Go ahead and try it!</p>
</div>
  
  


    </article>
  
  
    <article>
      
  <header>
    
      <h1 class="entry-title"><a href="/blog/three-reasons-why-im-ditching-chunkhost/">Three Reasons Why I&#8217;m Ditching ChunkHost</a></h1>
    
    
      <p class="meta">
        








  


<time datetime="2010-10-04T00:00:00-07:00" pubdate data-updated="true">Oct 4<span>th</span>, 2010</time>
        
      </p>
    
  </header>


  <div class="entry-content"><h1 id="section"></h1>

<p>I’ve been using <a href="http://chunkhost.com/r/chdotnet">ChunkHost</a> for the past <strong>eight months</strong> to host my website and some minor web applications. After my short, free “beta” period I was given a 30% discount (forever) and billed like a normal customer. I’ve only had to pay <strong>$13.30</strong> a month for a Xen VPS with <strong>512MB RAM</strong>. This used to be pretty competitive <a href="http://blog.linode.com/2010/06/16/linode-turns-7-big-ram-increase/">until Linode increased the RAM for all of their VPS packages</a>. Unfortunately for ChunkHost, this Linode RAM increase and some recent events have persuaded me to <a href="http://www.linode.com/?r=2fce38a23c4154c3a1abb4f99aafd6371ee78ecc"><strong>pay the extra 7 bucks to Linode</strong></a>. Here are the three main reasons why I’m ditching ChunkHost:</p>

<ol>
  <li><strong>No way to give feedback on the service.</strong> First, let me qualify this and say that there <em>is</em> a “Feedback” button on the site. However, more than a quick cursory glance reveals that their feedback system is <strong>inactive **and **neglected</strong>. For example, I have an eight month old feature request that has gone ignored; not rejected, not WONTFIX’d, but ignored. Other customers have older feature requests that have been promised “shortly” and never delivered.<img src="http://cdn.subversity.net/blog_imgs/chunkhost-inactive.png" alt="An example of ChunkHost's inactive GetSatisfaction feedback page" title="chunkhost-inactive.png" /> 
  
    <ul>
      <li>
        <p><strong>There is no SLA (service-level agreement) or uptime guarantee.</strong> Recently, I noticed that my VM was down and the main page for ChunkHost was down as well. I emailed support about the outage and was happy to receive a quick reply.<br />
&gt; Yeah, we’re looking at it now; it looks like networking oddness on one of the host machines. We’ll update Twitter with info as we have it!</p>

        <p>The “fix” consisted of ChunkHost <strong>rebooting the physical host</strong> my VM was on. This same problem occurred *again <strong>*5 hours later</strong>. I don’t sense any empathy from ChunkHost for bearing with them through their downtime and I certainly haven’t received any type of apology. Am I entitled to one? With the lack of an SLA, maybe not, but I’d be alot less bitter and I might have remained a customer had I received one.</p>
      </li>
      <li>
        <p><strong>Not enough notice given for “scheduled” maintenance.</strong> Four days before the two outages I had experienced, ChunkHost performed some scheduled maintenance. I am thankful that the maintenance occurred in off-peak hours, but <strong>I received the notice at the end of the previous day</strong>. This is not adequate notice. Had there been anything critical running on my VM, I would expect adequate notice so I could make proper arrangements ahead of time. 
It saddens me to think that my last eight months at ChunkHost were a waste. Fortunately, <a href="http://www.linode.com/?r=2fce38a23c4154c3a1abb4f99aafd6371ee78ecc">I’ve been using Linode for my “real services” for just as long</a> and I know that I won’t be disappointed there. If you’re looking for a VM for testing and development purposes only, ChunkHost might be an option – just don’t let your development server evolve into a production server.</p>
      </li>
    </ul>
  </li>
</ol>

</div>
  
  


    </article>
  
  
    <article>
      
  <header>
    
      <h1 class="entry-title"><a href="/blog/i-think-and-think-for-months-and-years-99-times-the-conclusion-is-false-the-hundredth-time-i-am-right-einstein/">I Think and Think for Months and Years. 99 Times, the Conclusion Is False. The Hundredth Time I Am Right - Einstein</a></h1>
    
    
      <p class="meta">
        








  


<time datetime="2010-09-05T00:00:00-07:00" pubdate data-updated="true">Sep 5<span>th</span>, 2010</time>
        
      </p>
    
  </header>


  <div class="entry-content"><h1 id="section"></h1>

<p>“I think and think for months and years. Ninety-nine times, the conclusion is false. The hundredth time I am right.” — <a href="http://nobelprize.org/nobel_prizes/physics/laureates/1921/einstein-bio.html">Albert Einstein</a></p>

<p>I think Einstein was onto the <a href="http://www.sebastianmarshall.com/?p=195">equal-odds rule</a>.  </p>

</div>
  
  


    </article>
  
  
    <article>
      
  <header>
    
      <h1 class="entry-title"><a href="/blog/the-hn-effect-in-numbers/">The HN Effect in Numbers</a></h1>
    
    
      <p class="meta">
        








  


<time datetime="2010-08-24T00:00:00-07:00" pubdate data-updated="true">Aug 24<span>th</span>, 2010</time>
        
      </p>
    
  </header>


  <div class="entry-content"><h1 id="section"></h1>

<p>For the unfamiliar, I wrote an article about a week and a half ago titled <a href="http://blog.charleshooper.net/how-i-made-money-spamming-twitter-with-contex">How I Made Money Spamming Twitter with Contextual Book Suggestions</a> and promised that I would follow up with a post on the type of traffic I received. Not only did the article get to be pretty popular with the <a href="http://news.ycombinator.com/">Hacker News</a> crowd, republished in <a href="http://www.businessinsider.com/sai">Silicon Alley Insider</a>, and make me the recipient of a handful of wonderful emails but I even got to visit <a href="http://www.tracked.com/">tracked.com’s engineering team</a> and get schooled on machine learning techniques and A.I. (hi guys!) 
Something relevant I should mention is that, just a day before, I had migrated my <a href="http://posterous.com">Posterous</a> blog from one domain to its current place, <a href="http://blog.charleshooper.net">blog.charleshooper.net</a>. To anyone who’s curious, this was a totally painless process. Set up DNS first, update your Posterous settings, and set up 302 redirects so your links don’t break. 
<strong>Social Link-Sharing</strong><br />
Despite finishing my article at 1:00 AM, I thought it was pretty well-written and I wanted my story to be heard, so I decided to get a full night’s sleep, proof-read it in the morning, and submit the link to Reddit, Digg, and Hacker News. Besides the obvious benefits of proof-reading the article while fully-rested, I also recognized that most link-sharing sites weight votes based on time (or rather, some product of votes/time maybe) so submitting my article in the morning meant that it would first show up at the beginning of what I believe to be peak usage. So how’d I do? 
Reddit hated it.<br />
<img src="http://www.charleshooper.net/wp-content/uploads/Picture_1.png" alt="" /></p>

<p>Digg didn’t care.<br />
<img src="http://www.charleshooper.net/wp-content/uploads/Picture_2.png" alt="" /> 
And Hacker News loved it!<br />
<img src="http://www.charleshooper.net/wp-content/uploads/Picture_4.png" alt="" /> 
I also make use of Posterous’ “autopost” features and have all my new submissions get posted to Twitter and Facebook. According to Posterous, there were over 77 retweets of my article (most likely from the tweet storm that the Silicon Alley Insider bot and HN bots started) and 7 “likes” on Facebook. 
<strong>Traffic</strong><br />
According to Google Analytics, I’m not very popular. Before publishing my article, I received an average of about 30 visits a day. On the day I published my article, I observed a surge of over 4,600 visitors. From there, the numbers declined daily at a rate that looks very much like exponential decay. It took 10 days for my traffic to return to normal, but that day was a Sunday and the following Monday was almost twice as high (62 visits). For the number geeks, the set of numbers beginning with the peak is (4652, 2688, 1065, 452, 206, 138, 105). I got close with the expression <a href="http://www.wolframalpha.com/input/?i=graph f(x) = 4652e^(-0.6x); x from 0 to 6"><em>f(x) = 4652e^(-0.6x)</em></a> but that isn’t quite right (maybe I should treat my average visits as a constant.) 
Update: I’ve gotten much closer with <a href="http://www.wolframalpha.com/input/?i=table[ 2658e^(-0.94x) %2B 30, {x,0,5} ]">f(x) = 2658e^(-0.94x) 30</a></p>

<p><img src="http://www.charleshooper.net/wp-content/uploads/Picture_6-300x168.png" alt="" /> </p>

<p>Over the time period, my article received over 9,000 unique page views with a bounce rate of over 90% (~93% exit rate.) I remember reading an article a little while ago that stated, on single-page use cases, the bounce rate will always be close to the exit rate unless the analytics software “phones in” after some period of time to register the visit as something other than a bounce. I use Google Analytics and, unless I find out otherwise, I don’t think it does this (although, it does measure “time on page” so maybe it does and Google’s idea of a bounce is different than mine.) </p>

<p><img src="http://www.charleshooper.net/wp-content/uploads/Picture_7.png" alt="" /><br />
 <strong>Sources</strong><br />
My largest source of traffic was referring websites making up over 70% of it. Less than 2% was from search engines and I don’t even think that any of it was destined for my article. 
<img src="http://www.charleshooper.net/wp-content/uploads/Picture_9.png" alt="" /><br />
 As for the referring websites, I received traffic from all over. However, most of it was from <a href="http://news.ycombinator.com/">Hacker News</a>, <a href="http://TechMeme.com">TechMeme.com</a>, and <a href="http://Google.com">Google.com</a>. I looked into “<a href="http://google.com">google.com</a> / referral” versus “<a href="http://google.com">google.com</a> / organic” and the referrals mostly consisted of visitors using Google Reader. What isn’t shown below is the 113 <em>other</em> referring sites. The “<a href="http://daemonology.net">daemonology.net</a>” referral is a result of <a href="http://www.daemonology.net/hn-daily/">HN Daily</a>. As you can see, my top sources are primarily seeded by social media and social link-sharing websites. 
<img src="http://www.charleshooper.net/wp-content/uploads/Picture_8-300x198.png" alt="" /><br />
 <strong>Conclusion</strong><br />
To conclude, don’t under-value the social sites. If you want some organic link juice then utilize the “chatty” sites like Facebook and Twitter as well as the link-sharing sites such as Hacker News, Reddit, and Digg. There is a hidden benefit to putting yourself out there and asking for alot of attention: You will ensure that your articles, blog posts, and research are high-quality resources of <em>useful</em> information. Essentially, you end up treating each blog post as you would any startup. Experiment first. Create value second. The rest (profit, respect, esteem) comes easy.</p>

</div>
  
  


    </article>
  
  
    <article>
      
  <header>
    
      <h1 class="entry-title"><a href="/blog/new-urldomain-for-my-blog-formerly-subversity-net/">New URL/Domain for My Blog (Formerly subversity.net)</a></h1>
    
    
      <p class="meta">
        








  


<time datetime="2010-08-13T00:00:00-07:00" pubdate data-updated="true">Aug 13<span>th</span>, 2010</time>
        
      </p>
    
  </header>


  <div class="entry-content"><h1 id="section"></h1>

<p>As I stand before you sipping my celebratory <a href="http://beeradvocate.com/beer/profile/220/56613">Wilco Tango Foxtrot</a>, I would like to present to you <a href="http://blog.charleshooper.net/">the new home for my blog</a>. The reason for this migration is that I am downsizing the amount of under-utilized domains I renew each year. Please update your bookmarks accordingly :-)</p>

</div>
  
  


    </article>
  
  
    <article>
      
  <header>
    
      <h1 class="entry-title"><a href="/blog/how-i-made-money-spamming-twitter-with-contextual-book-suggestions/">How I Made Money Spamming Twitter With Contextual Book Suggestions</a></h1>
    
    
      <p class="meta">
        








  


<time datetime="2010-08-13T00:00:00-07:00" pubdate data-updated="true">Aug 13<span>th</span>, 2010</time>
        
      </p>
    
  </header>


  <div class="entry-content"><h1 id="section"></h1>

<p>Two winters ago I left a position as a system administrator that was paying pretty well and moved cross-country to a region with less jobs than where I moved from. Three months later, I was still unemployed, broke, and bored. I was talking to my good friend <a href="http://japherwocky.posterous.com/">Japhy</a> on IRC one day and he was explaining to me how the <a href="http://en.wikipedia.org/wiki/Tf–idf">tf-idf algorithm</a> works. For reasons involving boredom more than any other reason, I dreamed up an idea: <strong>I would write software that would take a given document and generate book suggestions based on its content.</strong> </p>

<p>I think that most programmers would agree with me that we put in longer hours on code when we’re not working for anybody. We don’t stop learning, either. To us, <em>unemployment is a brief sprint of academia</em> spent in our home office, the local coffee shop, or our parent’s house. 
My imagination dreamed up this fairly straightforward process:</p>

<ol>
  <li>Take a given document and calculate tf-idf scores on all terms</li>
  <li>Select X number of the highest scoring terms</li>
  <li>Pass these high-scoring terms to an Amazon ItemSearch query</li>
  <li>Receive a list of recommended books (with URLs) from Amazon</li>
</ol>

<p>I had already written multiple Twitter bots by this time so I decided to just use some of my existing code to poll Twitter’s search API. Essentially, the “documents” I mentioned above were actually tweets containing the terms “book” or “books.” Two and a half days later I had a working prototype that could generate a book recommendation from a given tweet. It was at this time that I added steps 5 and 6:</p>

<p>Tag URLs returned from Amazon’s ItemSearch with an affiliate ID; and<br />
Reply to the tweeting user with their new book suggestion</p>

<p>Four months later and <strong>I had generated over $7,000 in sales for Amazon with over $400 commission for myself</strong>. Obviously, the commission I was making wasn’t livable but it was a nice addition to my then-depleting savings. Had I decided to scale out my operation, I could have made much more. My benchmark is at four months because that’s how long I went before being <em>suspended</em>. My conversion rate? <strong>0.13%</strong>! While seemingly low, this number is very high when compared to email spam. However, it’s important to note that email spam is subject to various filtering technologies. 
<img src="http://cdn.subversity.net/blog_imgs/twitter-spam-earnings.png" alt="twitter-spam-earnings.png" title="twitter-spam-earnings.png" /> 
A fair amount of the time I share this story, people are more impressed with the fact that I went 4 months before getting suspended. The truth is, I had a lot of throttling built into my spam bot. The factors I think are important to point out are:</p>

<ol>
  <li>Twitter’s Terms of Service at that time basically only outlawed “unsolicited replies,” nothing that really attacked targeted spam.</li>
  <li>Twitter’s anti-spam stance did exist in writing (only in the help site,) but I do not think they were actively enforcing their policies.</li>
  <li>My recommendations were contextual and, unless you looked at my bot’s timeline and tweet count, looked legitimate (most of the time.) In other words, I was tweeting <em>book suggestions</em> to people who were already talking about <em>books</em>.</li>
  <li>I recorded the usernames of everyone I sent recommendations to and would only @mention them once.</li>
  <li>I built in a “chattiness” rate limiting function. This was to distribute my spam throughout a whole hour (due to Twitter’s rate limiting) more than anything.</li>
</ol>

<p><img src="http://cdn.subversity.net/blog_imgs/twitter-suspended.png" alt="twitter-suspended.png" title="twitter-suspended.png" /> </p>

<p>While it only lasted a short while, I had alot of fun and made a little bit of money spamming Twitter. </p>

<p>The second re-incarnation of this project turned into <a href="http://www.charleshooper.net/twitter/">BookSuggest, a website for recommending books based on a person’s Twitter feed</a>. I haven’t put alot of effort into promoting it, but my conversion rate is much lower now that I’m not pushing the links in anyone’s face. </p>

<p>Try it out and comment here – what did BookSuggest tell YOU to read?</p>

</div>
  
  


    </article>
  
  <div class="pagination">
    
      <a class="prev" href="/blog/page/6/">&larr; Older</a>
    
    <a href="/blog/archives">Blog Archives</a>
    
    <a class="next" href="/blog/page/4/">Newer &rarr;</a>
    
  </div>
</div>
<aside class="sidebar">
  
    <section>
  <!-- Ads removed -->
</section>
<section>
  <h1>About Charles</h1>
	<img src="http://www.gravatar.com/avatar/9f645d339b731bc99a95704ad4289aac.png?size=160" alt="Charles Hooper"/>
	<p>Charles is an engineering manager at Heroku. He enjoys archery, smoking meat, gardening, home brewing, and hacking.</p>
</section>
<section>
  <h1>Recent Posts</h1>
  <ul id="recent_posts">
    
      <li class="post">
        <a href="/blog/on-slack-and-upkeep/">On Slack and Upkeep</a>
      </li>
    
      <li class="post">
        <a href="/blog/what-i-do-sre/">What I Do as an SRE</a>
      </li>
    
      <li class="post">
        <a href="/blog/troubleshooting-elbs-with-elbping/">Troubleshooting ELBs with elbping</a>
      </li>
    
      <li class="post">
        <a href="/blog/my-def-con-21-experience/">My DEF CON 21 Experience</a>
      </li>
    
      <li class="post">
        <a href="/blog/why-i-moved-to-san-francisco/">Why I moved to San Francisco</a>
      </li>
    
  </ul>
</section>

<section>
  <!-- Ads removed -->
</section>

  
</aside>

    </div>
  </div>
  <footer role="contentinfo"><p>
  Copyright &copy; 2015 - Charles Hooper -
  <span class="credit">Powered by <a href="http://octopress.org">Octopress</a></span>
</p>

</footer>
  

<script type="text/javascript">
      var disqus_shortname = 'charleshooper';
      
        
        var disqus_script = 'count.js';
      
    (function () {
      var dsq = document.createElement('script'); dsq.type = 'text/javascript'; dsq.async = true;
      dsq.src = 'http://' + disqus_shortname + '.disqus.com/' + disqus_script;
      (document.getElementsByTagName('head')[0] || document.getElementsByTagName('body')[0]).appendChild(dsq);
    }());
</script>







  <script type="text/javascript">
    (function(){
      var twitterWidgets = document.createElement('script');
      twitterWidgets.type = 'text/javascript';
      twitterWidgets.async = true;
      twitterWidgets.src = 'http://platform.twitter.com/widgets.js';
      document.getElementsByTagName('head')[0].appendChild(twitterWidgets);
    })();
  </script>





</body>
</html>
