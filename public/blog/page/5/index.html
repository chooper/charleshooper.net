
<!DOCTYPE html>
<!--[if IEMobile 7 ]><html class="no-js iem7"><![endif]-->
<!--[if lt IE 9]><html class="no-js lte-ie8"><![endif]-->
<!--[if (gt IE 8)|(gt IEMobile 7)|!(IEMobile)|!(IE)]><!--><html class="no-js" lang="en"><!--<![endif]-->
<head>
  <meta charset="utf-8">
  <title>Charles Hooper</title>
  <meta name="author" content="Charles Hooper">

  
  <meta name="description" content="BookSuggest, the web-based book recommendation engine, is officially dead. I’ve been treating BookSuggest as the lowest of priorities for quite some &hellip;">
  

  <!-- http://t.co/dKP3o1e -->
  <meta name="HandheldFriendly" content="True">
  <meta name="MobileOptimized" content="320">
  <meta name="viewport" content="width=device-width, initial-scale=1">

  
  <link rel="canonical" href="http://www.charleshooper.net/blog/page/5">
  <link href="/favicon.png" rel="icon">
  <link href="/stylesheets/screen.css" media="screen, projection" rel="stylesheet" type="text/css">
  <link href="http://feeds.feedburner.com/subversity" rel="alternate" title="Charles Hooper" type="application/atom+xml">
  <script src="/javascripts/modernizr-2.0.js"></script>
  <script src="//ajax.googleapis.com/ajax/libs/jquery/1.9.1/jquery.min.js"></script>
  <script>!window.jQuery && document.write(unescape('%3Cscript src="./javascripts/lib/jquery.min.js"%3E%3C/script%3E'))</script>
  <script src="/javascripts/octopress.js" type="text/javascript"></script>
  <!--Fonts from Google"s Web font directory at http://google.com/webfonts -->
<link href="http://fonts.googleapis.com/css?family=PT+Serif:regular,italic,bold,bolditalic" rel="stylesheet" type="text/css">
<link href="http://fonts.googleapis.com/css?family=PT+Sans:regular,italic,bold,bolditalic" rel="stylesheet" type="text/css">

  
  <script type="text/javascript">
    var _gaq = _gaq || [];
    _gaq.push(['_setAccount', 'UA-12888528-1']);
    _gaq.push(['_trackPageview']);

    setTimeout("_gaq.push(['_trackEvent', '60_seconds', 'read'])", 60000);

    (function() {
      var ga = document.createElement('script'); ga.type = 'text/javascript'; ga.async = true;
      ga.src = ('https:' == document.location.protocol ? 'https://ssl' : 'http://www') + '.google-analytics.com/ga.js';
      var s = document.getElementsByTagName('script')[0]; s.parentNode.insertBefore(ga, s);
    })();
  </script>



</head>

<body   >
  <header role="banner"><hgroup>
  <h1><a href="/">Charles Hooper</a></h1>
  
    <h2>Thoughts and projects from a Hacker and Operations Engineer</h2>
  
</hgroup>

</header>
  <nav role="navigation"><ul class="subscription" data-subscription="rss">
  <li><a href="http://feeds.feedburner.com/subversity" rel="subscribe-rss" title="subscribe via RSS">RSS</a></li>
  
</ul>
  
<form action="http://google.com/search" method="get">
  <fieldset role="search">
    <input type="hidden" name="q" value="site:www.charleshooper.net" />
    <input class="search" type="text" name="q" results="0" placeholder="Search"/>
  </fieldset>
</form>
  
<ul class="main-navigation">
  <li><a href="/">Blog</a></li>
	<li><a href="/about/">About Charles</a></li>
	<li><a href="/projects/">Projects</a></li>
	<li><a href="/contact/">Contact</a></li>
  <li><a href="/blog/archives">Archives</a></li>
</ul>

</nav>
  <div id="main">
    <div id="content">
      <div class="blog-index">
  
  
  
    <article>
      
  <header>
    
      <h1 class="entry-title"><a href="/blog/rip-booksuggest/">RIP BookSuggest</a></h1>
    
    
      <p class="meta">
        








  


<time datetime="2010-10-26T00:00:00-07:00" pubdate data-updated="true">Oct 26<span>th</span>, 2010</time>
        
      </p>
    
  </header>


  <div class="entry-content"><h1 id="section"></h1>

<p>BookSuggest, the web-based book recommendation engine, is officially dead. I’ve been treating BookSuggest as the lowest of priorities for quite some time now and I’m more than happy to declare this project a failure. Here is a brief recap of BookSuggest’s history.</p>

<p>Before BookSuggest was a web application, I used to <a href="http://www.charleshooper.net/blog/how-i-made-money-spamming-twitter-with-contextual-book-suggestions/">spam unsuspecting Twitter users</a> with book recommendations. Eventually, Twitter stepped up their anti-spam stance and suspended my spam account. I retired the project for a while until one day I decided to build a web application around the recommendation technology I was using.</p>

<p>This technology was simply scoring words in a user’s timeline, taking the four highest-scoring words, and then passing them to an Amazon ItemSearch query. More specifically, the type of search in use was what Amazon calls a TextStream search. This search method is what allowed me to get book recommendations, even if the search terms provided weren’t all that great. Without it, it’s not unlikely that my ItemSearches wouldn’t return any results at all.</p>

<p>So imagine my surprise when I read the following in Amazon’s API documentation:</p>

<blockquote>
  <p>Due to low usage, the Product Advertising API operations and response groups listed below will not be supported after October 15, 2010:</p>

  <p>…<br />
Additionally, due to low usage, we will be discontinuing Multiple Operation Requests and the <strong>TextStream</strong> search parameter.</p>
</blockquote>

<p>Oh, shoot!</p>

<p>Financially, it makes sense for me to cut my losses here. Back when I was still spamming Twitter, I was pulling over $100/mo. Through the web-app, my referral fees are much smaller. As of this moment, I have a balance of just $9 with Amazon and haven’t cashed out since the start of the project.</p>

<p>Some numbers:</p>

<ul>
  <li>Unique Twitter users: 393</li>
  <li>Recommendations made: 611</li>
  <li>Documents in corpus: 17,458,549</li>
  <li>Unique words in corpus: 1,970,165</li>
  <li>Top 5 words in corpus: that, just, with, this, have</li>
</ul>

<p>RIP BookSuggest!</p>
</div>
  
  


    </article>
  
  
    <article>
      
  <header>
    
      <h1 class="entry-title"><a href="/blog/code-responsibly/">Code Responsibly: What&#8217;s Best for Your Clients?</a></h1>
    
    
      <p class="meta">
        








  


<time datetime="2010-10-23T00:00:00-07:00" pubdate data-updated="true">Oct 23<span>rd</span>, 2010</time>
        
      </p>
    
  </header>


  <div class="entry-content"><h1 id="section"></h1>

<p>We programmers have a natural affinity for writing and using our own code. You can’t really blame us; this is akin to gardeners who prefer to eat vegetables they grow, or brewers who prefer to drink their own beer. However, this oftentimes leads to a frequent re-invention of the wheel. While this isn’t always a bad thing, it doesn’t usually benefit our clients and here’s why:</p>

<ol>
  <li>**Increased development time. **If a client is paying you hourly, why should they pay for you to re-invent a solution that already exists? Why write a new CMS if WordPress will do? When you write a new CMS from scratch for a client, you are increasing their development costs.</li>
  <li>**Freedom in hosting. **It’s no coincidence that many web developers also host their projects as well. This is fine for larger applications, but for the majority of the client work out there your clients should have the freedom to a broad range of hosting options. Vendor lock-in is a terrible thing.</li>
  <li>**Post-development support. **If a client needs customizations done to the code base, they should be able to solicit the work from almost any developer. Certainly you would want preference in these solicitations, but there shouldn’t be any clients who are stuck with you. When you use your own custom solution, you are increasing your clients’ maintenance costs.</li>
</ol>

<p>I’m <em>not</em> saying that you shouldn’t ever write new code. What I <em>am</em> saying is that your responsibility to the client is to use the best tools for the job and to put together the best solution for them that you can. Sometimes this means flexing your coding muscles and sometimes this means humbly setting up existing software such as WordPress. So please, write new code conservatively and responsibly.</p>
</div>
  
  


    </article>
  
  
    <article>
      
  <header>
    
      <h1 class="entry-title"><a href="/blog/validating-data-with-new-style-classes-in-python/">Validating Data With New-Style Classes in Python</a></h1>
    
    
      <p class="meta">
        








  


<time datetime="2010-10-11T00:00:00-07:00" pubdate data-updated="true">Oct 11<span>th</span>, 2010</time>
        
      </p>
    
  </header>


  <div class="entry-content"><h1 id="section"></h1>

<p>Every once in awhile in my reading I come across a minor reference to what pythonistas refer to as <strong>new-style classes</strong>. One of the nice things about new-style classes is the `property` decorators. These property decorators allow you to build getter and setter methods to access object attributes. This is pretty awesome because now you can perform validation at the model/class level whenever you assign a value to a property of an object.</p>

<p>e.g., In one of my projects, I have an attribute named <em>timestamp</em> that takes a `datetime` object. I was concerned about receiving incorrect types from my input because there are alot of ways a programmer can represent the concept of time. Some realistic possibilities of invalid types in my case are:</p>

<ul>
  <li>`time` objects from the time module</li>
  <li>`string` objects that contain the date and time (and various possible formats)</li>
  <li>`float` or `int` objects that contain a unix timestamp</li>
</ul>

<p>With a setter method, you can test that the new value being assigned to an attribute is the correct type before assigning it. You can also throw an <strong>exception</strong> if it’s not. In other words, you can do something like this:</p>

<pre><code>from datetime import datetime

class SomeObject(object):    # new-style classes must be subclassed from object
    _timestamp = None

    @property
    def timestamp(self):
        return self._timestamp

    @timestamp.setter    # the prefix must match the read-only getter func name
    def timestamp(self,value):    # the func name must match the read-only getter func name
        if not isinstance(value, datetime):
            raise ValueError(“Timestamp can only be an instance of Datetime”)
        self._timestamp = value
</code></pre>

<p>Go ahead and try it!</p>
</div>
  
  


    </article>
  
  
    <article>
      
  <header>
    
      <h1 class="entry-title"><a href="/blog/three-reasons-why-im-ditching-chunkhost/">Three Reasons Why I&#8217;m Ditching ChunkHost</a></h1>
    
    
      <p class="meta">
        








  


<time datetime="2010-10-04T00:00:00-07:00" pubdate data-updated="true">Oct 4<span>th</span>, 2010</time>
        
      </p>
    
  </header>


  <div class="entry-content"><h1 id="section"></h1>

<p>I’ve been using <a href="http://chunkhost.com/r/chdotnet">ChunkHost</a> for the past <strong>eight months</strong> to host my website and some minor web applications. After my short, free “beta” period I was given a 30% discount (forever) and billed like a normal customer. I’ve only had to pay <strong>$13.30</strong> a month for a Xen VPS with <strong>512MB RAM</strong>. This used to be pretty competitive <a href="http://blog.linode.com/2010/06/16/linode-turns-7-big-ram-increase/">until Linode increased the RAM for all of their VPS packages</a>. Unfortunately for ChunkHost, this Linode RAM increase and some recent events have persuaded me to <a href="http://www.linode.com/?r=2fce38a23c4154c3a1abb4f99aafd6371ee78ecc"><strong>pay the extra 7 bucks to Linode</strong></a>. Here are the three main reasons why I’m ditching ChunkHost:</p>

<ol>
  <li><strong>No way to give feedback on the service.</strong> First, let me qualify this and say that there <em>is</em> a “Feedback” button on the site. However, more than a quick cursory glance reveals that their feedback system is <strong>inactive **and **neglected</strong>. For example, I have an eight month old feature request that has gone ignored; not rejected, not WONTFIX’d, but ignored. Other customers have older feature requests that have been promised “shortly” and never delivered.<img src="http://cdn.subversity.net/blog_imgs/chunkhost-inactive.png" alt="An example of ChunkHost's inactive GetSatisfaction feedback page" title="chunkhost-inactive.png" /> 
  
    <ul>
      <li>
        <p><strong>There is no SLA (service-level agreement) or uptime guarantee.</strong> Recently, I noticed that my VM was down and the main page for ChunkHost was down as well. I emailed support about the outage and was happy to receive a quick reply.<br />
&gt; Yeah, we’re looking at it now; it looks like networking oddness on one of the host machines. We’ll update Twitter with info as we have it!</p>

        <p>The “fix” consisted of ChunkHost <strong>rebooting the physical host</strong> my VM was on. This same problem occurred *again <strong>*5 hours later</strong>. I don’t sense any empathy from ChunkHost for bearing with them through their downtime and I certainly haven’t received any type of apology. Am I entitled to one? With the lack of an SLA, maybe not, but I’d be alot less bitter and I might have remained a customer had I received one.</p>
      </li>
      <li>
        <p><strong>Not enough notice given for “scheduled” maintenance.</strong> Four days before the two outages I had experienced, ChunkHost performed some scheduled maintenance. I am thankful that the maintenance occurred in off-peak hours, but <strong>I received the notice at the end of the previous day</strong>. This is not adequate notice. Had there been anything critical running on my VM, I would expect adequate notice so I could make proper arrangements ahead of time. 
It saddens me to think that my last eight months at ChunkHost were a waste. Fortunately, <a href="http://www.linode.com/?r=2fce38a23c4154c3a1abb4f99aafd6371ee78ecc">I’ve been using Linode for my “real services” for just as long</a> and I know that I won’t be disappointed there. If you’re looking for a VM for testing and development purposes only, ChunkHost might be an option – just don’t let your development server evolve into a production server.</p>
      </li>
    </ul>
  </li>
</ol>

</div>
  
  


    </article>
  
  
    <article>
      
  <header>
    
      <h1 class="entry-title"><a href="/blog/i-think-and-think-for-months-and-years-99-times-the-conclusion-is-false-the-hundredth-time-i-am-right-einstein/">I Think and Think for Months and Years. 99 Times, the Conclusion Is False. The Hundredth Time I Am Right - Einstein</a></h1>
    
    
      <p class="meta">
        








  


<time datetime="2010-09-05T00:00:00-07:00" pubdate data-updated="true">Sep 5<span>th</span>, 2010</time>
        
      </p>
    
  </header>


  <div class="entry-content"><h1 id="section"></h1>

<p>“I think and think for months and years. Ninety-nine times, the conclusion is false. The hundredth time I am right.” — <a href="http://nobelprize.org/nobel_prizes/physics/laureates/1921/einstein-bio.html">Albert Einstein</a></p>

<p>I think Einstein was onto the <a href="http://www.sebastianmarshall.com/?p=195">equal-odds rule</a>.  </p>

</div>
  
  


    </article>
  
  
    <article>
      
  <header>
    
      <h1 class="entry-title"><a href="/blog/the-hn-effect-in-numbers/">The HN Effect in Numbers</a></h1>
    
    
      <p class="meta">
        








  


<time datetime="2010-08-24T00:00:00-07:00" pubdate data-updated="true">Aug 24<span>th</span>, 2010</time>
        
      </p>
    
  </header>


  <div class="entry-content"><h1 id="section"></h1>

<p>For the unfamiliar, I wrote an article about a week and a half ago titled <a href="http://blog.charleshooper.net/how-i-made-money-spamming-twitter-with-contex">How I Made Money Spamming Twitter with Contextual Book Suggestions</a> and promised that I would follow up with a post on the type of traffic I received. Not only did the article get to be pretty popular with the <a href="http://news.ycombinator.com/">Hacker News</a> crowd, republished in <a href="http://www.businessinsider.com/sai">Silicon Alley Insider</a>, and make me the recipient of a handful of wonderful emails but I even got to visit <a href="http://www.tracked.com/">tracked.com’s engineering team</a> and get schooled on machine learning techniques and A.I. (hi guys!) 
Something relevant I should mention is that, just a day before, I had migrated my <a href="http://posterous.com">Posterous</a> blog from one domain to its current place, <a href="http://blog.charleshooper.net">blog.charleshooper.net</a>. To anyone who’s curious, this was a totally painless process. Set up DNS first, update your Posterous settings, and set up 302 redirects so your links don’t break. 
<strong>Social Link-Sharing</strong><br />
Despite finishing my article at 1:00 AM, I thought it was pretty well-written and I wanted my story to be heard, so I decided to get a full night’s sleep, proof-read it in the morning, and submit the link to Reddit, Digg, and Hacker News. Besides the obvious benefits of proof-reading the article while fully-rested, I also recognized that most link-sharing sites weight votes based on time (or rather, some product of votes/time maybe) so submitting my article in the morning meant that it would first show up at the beginning of what I believe to be peak usage. So how’d I do? 
Reddit hated it.<br />
<img src="http://www.charleshooper.net/wp-content/uploads/Picture_1.png" alt="" /></p>

<p>Digg didn’t care.<br />
<img src="http://www.charleshooper.net/wp-content/uploads/Picture_2.png" alt="" /> 
And Hacker News loved it!<br />
<img src="http://www.charleshooper.net/wp-content/uploads/Picture_4.png" alt="" /> 
I also make use of Posterous’ “autopost” features and have all my new submissions get posted to Twitter and Facebook. According to Posterous, there were over 77 retweets of my article (most likely from the tweet storm that the Silicon Alley Insider bot and HN bots started) and 7 “likes” on Facebook. 
<strong>Traffic</strong><br />
According to Google Analytics, I’m not very popular. Before publishing my article, I received an average of about 30 visits a day. On the day I published my article, I observed a surge of over 4,600 visitors. From there, the numbers declined daily at a rate that looks very much like exponential decay. It took 10 days for my traffic to return to normal, but that day was a Sunday and the following Monday was almost twice as high (62 visits). For the number geeks, the set of numbers beginning with the peak is (4652, 2688, 1065, 452, 206, 138, 105). I got close with the expression <a href="http://www.wolframalpha.com/input/?i=graph f(x) = 4652e^(-0.6x); x from 0 to 6"><em>f(x) = 4652e^(-0.6x)</em></a> but that isn’t quite right (maybe I should treat my average visits as a constant.) 
Update: I’ve gotten much closer with <a href="http://www.wolframalpha.com/input/?i=table[ 2658e^(-0.94x) %2B 30, {x,0,5} ]">f(x) = 2658e^(-0.94x) 30</a></p>

<p><img src="http://www.charleshooper.net/wp-content/uploads/Picture_6-300x168.png" alt="" /> </p>

<p>Over the time period, my article received over 9,000 unique page views with a bounce rate of over 90% (~93% exit rate.) I remember reading an article a little while ago that stated, on single-page use cases, the bounce rate will always be close to the exit rate unless the analytics software “phones in” after some period of time to register the visit as something other than a bounce. I use Google Analytics and, unless I find out otherwise, I don’t think it does this (although, it does measure “time on page” so maybe it does and Google’s idea of a bounce is different than mine.) </p>

<p><img src="http://www.charleshooper.net/wp-content/uploads/Picture_7.png" alt="" /><br />
 <strong>Sources</strong><br />
My largest source of traffic was referring websites making up over 70% of it. Less than 2% was from search engines and I don’t even think that any of it was destined for my article. 
<img src="http://www.charleshooper.net/wp-content/uploads/Picture_9.png" alt="" /><br />
 As for the referring websites, I received traffic from all over. However, most of it was from <a href="http://news.ycombinator.com/">Hacker News</a>, <a href="http://TechMeme.com">TechMeme.com</a>, and <a href="http://Google.com">Google.com</a>. I looked into “<a href="http://google.com">google.com</a> / referral” versus “<a href="http://google.com">google.com</a> / organic” and the referrals mostly consisted of visitors using Google Reader. What isn’t shown below is the 113 <em>other</em> referring sites. The “<a href="http://daemonology.net">daemonology.net</a>” referral is a result of <a href="http://www.daemonology.net/hn-daily/">HN Daily</a>. As you can see, my top sources are primarily seeded by social media and social link-sharing websites. 
<img src="http://www.charleshooper.net/wp-content/uploads/Picture_8-300x198.png" alt="" /><br />
 <strong>Conclusion</strong><br />
To conclude, don’t under-value the social sites. If you want some organic link juice then utilize the “chatty” sites like Facebook and Twitter as well as the link-sharing sites such as Hacker News, Reddit, and Digg. There is a hidden benefit to putting yourself out there and asking for alot of attention: You will ensure that your articles, blog posts, and research are high-quality resources of <em>useful</em> information. Essentially, you end up treating each blog post as you would any startup. Experiment first. Create value second. The rest (profit, respect, esteem) comes easy.</p>

</div>
  
  


    </article>
  
  
    <article>
      
  <header>
    
      <h1 class="entry-title"><a href="/blog/new-urldomain-for-my-blog-formerly-subversity-net/">New URL/Domain for My Blog (Formerly subversity.net)</a></h1>
    
    
      <p class="meta">
        








  


<time datetime="2010-08-13T00:00:00-07:00" pubdate data-updated="true">Aug 13<span>th</span>, 2010</time>
        
      </p>
    
  </header>


  <div class="entry-content"><h1 id="section"></h1>

<p>As I stand before you sipping my celebratory <a href="http://beeradvocate.com/beer/profile/220/56613">Wilco Tango Foxtrot</a>, I would like to present to you <a href="http://blog.charleshooper.net/">the new home for my blog</a>. The reason for this migration is that I am downsizing the amount of under-utilized domains I renew each year. Please update your bookmarks accordingly :-)</p>

</div>
  
  


    </article>
  
  
    <article>
      
  <header>
    
      <h1 class="entry-title"><a href="/blog/how-i-made-money-spamming-twitter-with-contextual-book-suggestions/">How I Made Money Spamming Twitter With Contextual Book Suggestions</a></h1>
    
    
      <p class="meta">
        








  


<time datetime="2010-08-13T00:00:00-07:00" pubdate data-updated="true">Aug 13<span>th</span>, 2010</time>
        
      </p>
    
  </header>


  <div class="entry-content"><h1 id="section"></h1>

<p>Two winters ago I left a position as a system administrator that was paying pretty well and moved cross-country to a region with less jobs than where I moved from. Three months later, I was still unemployed, broke, and bored. I was talking to my good friend <a href="http://japherwocky.posterous.com/">Japhy</a> on IRC one day and he was explaining to me how the <a href="http://en.wikipedia.org/wiki/Tf–idf">tf-idf algorithm</a> works. For reasons involving boredom more than any other reason, I dreamed up an idea: <strong>I would write software that would take a given document and generate book suggestions based on its content.</strong> </p>

<p>I think that most programmers would agree with me that we put in longer hours on code when we’re not working for anybody. We don’t stop learning, either. To us, <em>unemployment is a brief sprint of academia</em> spent in our home office, the local coffee shop, or our parent’s house. 
My imagination dreamed up this fairly straightforward process:</p>

<ol>
  <li>Take a given document and calculate tf-idf scores on all terms</li>
  <li>Select X number of the highest scoring terms</li>
  <li>Pass these high-scoring terms to an Amazon ItemSearch query</li>
  <li>Receive a list of recommended books (with URLs) from Amazon</li>
</ol>

<p>I had already written multiple Twitter bots by this time so I decided to just use some of my existing code to poll Twitter’s search API. Essentially, the “documents” I mentioned above were actually tweets containing the terms “book” or “books.” Two and a half days later I had a working prototype that could generate a book recommendation from a given tweet. It was at this time that I added steps 5 and 6:</p>

<p>Tag URLs returned from Amazon’s ItemSearch with an affiliate ID; and<br />
Reply to the tweeting user with their new book suggestion</p>

<p>Four months later and <strong>I had generated over $7,000 in sales for Amazon with over $400 commission for myself</strong>. Obviously, the commission I was making wasn’t livable but it was a nice addition to my then-depleting savings. Had I decided to scale out my operation, I could have made much more. My benchmark is at four months because that’s how long I went before being <em>suspended</em>. My conversion rate? <strong>0.13%</strong>! While seemingly low, this number is very high when compared to email spam. However, it’s important to note that email spam is subject to various filtering technologies. 
<img src="http://cdn.subversity.net/blog_imgs/twitter-spam-earnings.png" alt="twitter-spam-earnings.png" title="twitter-spam-earnings.png" /> 
A fair amount of the time I share this story, people are more impressed with the fact that I went 4 months before getting suspended. The truth is, I had a lot of throttling built into my spam bot. The factors I think are important to point out are:</p>

<ol>
  <li>Twitter’s Terms of Service at that time basically only outlawed “unsolicited replies,” nothing that really attacked targeted spam.</li>
  <li>Twitter’s anti-spam stance did exist in writing (only in the help site,) but I do not think they were actively enforcing their policies.</li>
  <li>My recommendations were contextual and, unless you looked at my bot’s timeline and tweet count, looked legitimate (most of the time.) In other words, I was tweeting <em>book suggestions</em> to people who were already talking about <em>books</em>.</li>
  <li>I recorded the usernames of everyone I sent recommendations to and would only @mention them once.</li>
  <li>I built in a “chattiness” rate limiting function. This was to distribute my spam throughout a whole hour (due to Twitter’s rate limiting) more than anything.</li>
</ol>

<p><img src="http://cdn.subversity.net/blog_imgs/twitter-suspended.png" alt="twitter-suspended.png" title="twitter-suspended.png" /> </p>

<p>While it only lasted a short while, I had alot of fun and made a little bit of money spamming Twitter. </p>

<p>The second re-incarnation of this project turned into <a href="http://www.charleshooper.net/twitter/">BookSuggest, a website for recommending books based on a person’s Twitter feed</a>. I haven’t put alot of effort into promoting it, but my conversion rate is much lower now that I’m not pushing the links in anyone’s face. </p>

<p>Try it out and comment here – what did BookSuggest tell YOU to read?</p>

</div>
  
  


    </article>
  
  
    <article>
      
  <header>
    
      <h1 class="entry-title"><a href="/blog/what-are-the-generally-accepted-accounting-principles-gaap/">What Are the Generally Accepted Accounting Principles (GAAP)?</a></h1>
    
    
      <p class="meta">
        








  


<time datetime="2010-07-24T00:00:00-07:00" pubdate data-updated="true">Jul 24<span>th</span>, 2010</time>
        
      </p>
    
  </header>


  <div class="entry-content"><h1 id="section"></h1>

<p>This entry is part 3 of 8 in the series<a href="http://www.charleshooper.net/blog/series/intro-to-financial-reporting/" title="Intro to Financial Reporting">Intro to Financial Reporting</a></p>

<p>Previously, we discussed the various regulations and regulatory bodies that govern financial reporting. We will now turn to the Generally Accepted Accounting Principles (GAAP) to explain the basic principles used in accounting. In particular, we will discuss the cost, revenue recognition, matching, and full disclosure principles.</p>

<p>While it may sound redundant, the cost principle means that “accounting information is based on an actual cost” (Wild, Shaw, &amp; Chiappetta, 2009, p. 9). In other words, everything is treated as having the value of what was paid for it. So what happens when businesses make a trade or don’t purchase with cash (businesses have been known to buy each other with a mix of cash, stocks, and bonds)? “If something besides cash is exchanged … cost is measured as the cash value of what is given up or received” (Wild, Shaw, &amp; Chiappetta, 2009, p. 10). That caveat here is that if you buy something and get a good deal, such as buying a $7000 asset for $5000, the item will be recognized in your accounting system as having a value of $5000. This is to ensure that the accounting information remains objective (Wild, Shaw, &amp; Chiappetta, 2009, p. 10). Next, we will look at the revenue recognition principle.</p>

<p>The revenue recognition principle determines how and when a company will recognize (record) revenue (Wild, Shaw, &amp; Chiappetta, 2009, p. 10). The primary concept of the revenue recognition principle is that “Revenue is recognized when earned” (Wild, Shaw, &amp; Chiappetta, 2009, p. 10). This doesn’t necessarily mean when the customer or client pays for their good or service, but when the good or service is actually sold (such as on credit). For example, if I configured someone’s network (a service) at an hourly rate, I would be required to recognize and record this earned revenue as soon as the work is done; this is usually done crediting accounts receivable (most accounting software does this automatically when generating an invoice.) This principle is intended to keep companies from recognizing revenue too early to look more profitable while also ensuring that they don’t recognize revenue too late to look less profitable than they really are (Wild, Shaw, &amp; Chiappetta, 2009, p. 10). Now let’s look to the matching principle.</p>

<p>The matching principle dictates that a company must report its expenses in the period that they generated the revenue reported (Wild, Shaw, &amp; Chiappetta, 2009, p. 10). Let’s say, for example, that a company buys 10 pounds of raw material, uses it to make 10 widgets, and then sells 5 of those widgets. Under the matching principle, the company would report the expenses (or, in this case, Cost of Goods Sold) incurred to make the 5 widgets it sold. The remaining 5 (that are now sitting in inventory), would not have their expenses/COGS reported until they too were sold. Finally, we turn to the full disclosure principle.</p>

<p>The full disclosure principle is probably the most basic yet most important principle. The full disclosure principle states that a company must “report the details behind financial statements that would impact users’ decisions” (Wild, Shaw, &amp; Chiappetta, 2009, p. 10). Oftentimes, these details are reported in footnotes of a company’s financial statements or annual reports (Wild, Shaw, &amp; Chiappetta, 2009, p. 10). An example of this from current events is Dell’s recent trouble with the SEC. Dell’s recent trouble was partially the result of receiving money from CPU manufacturer Intel and disguising that money as sales (why they hid it is another topic entirely). Users of Dell’s financial reports were led to believe that this extra money was the result of sales. When Intel stopped paying Dell this “incentive money,” Dell then took extra steps to falsify their financial statements to hide the fact that their revenue decreased. Save for the anti-trust violation with Intel, if Dell had just fully disclosed the revenue it was receiving from Intel they may have never felt the pressure to hide the fact that the payments stopped.</p>

<p>In conclusion, the Generally Accepted Accounting Principles (GAAP) are made up of four basic principles. In particular, we discussed the cost, revenue recognition, matching, and full disclosure principles.</p>

<p>Chiappetta, B., Shaw, K., Wild, J. (2009). Principles of Financial Accounting (19th ed.). McGraw-Hill/Irwin.</p>
</div>
  
  


    </article>
  
  
    <article>
      
  <header>
    
      <h1 class="entry-title"><a href="/blog/who-was-enron-and-why-is-this-important-to-financial-reporting-today/">Who Was Enron and Why Is This Important to Financial Reporting Today?</a></h1>
    
    
      <p class="meta">
        








  


<time datetime="2010-07-19T00:00:00-07:00" pubdate data-updated="true">Jul 19<span>th</span>, 2010</time>
        
      </p>
    
  </header>


  <div class="entry-content"><h1 id="section"></h1>

<p>This entry is part 6 of 8 in the series <a href="http://www.charleshooper.net/blog/series/intro-to-financial-reporting/" title="Intro to Financial Reporting">Intro to Financial Reporting</a></p>

<p>Enron was an energy trading company. Rather than generate energy
themselves, Enron made its money by buying and selling energy contracts.
At one point, Enron was considered one of the most innovative companies
on the market and reported sales of over $100 billion one year. Soon
after, the company then reported losses of $618 million loss in the
third quarter of 2001 (Nielsen, 2002, para. 1). A little later, the firm
filed for Chapter 11 bankruptcy. “The company’s Chapter 11 filing
[left] banks, pension plans and other lenders with at least $5 billion
at risk. More than 4,000 Enron employees lost their jobs and 401(k)
savings. The collapse reverberated the stock market, which dropped some
$200 billion in value since Enron’s Dec. 2 filing, amid fears that other
Enrons are lurking out there” (Jaffe, 2002, para. 3).</p>

<p>So how does a company go from reporting over $100 billion dollars in sales when they are really on the verge of bankruptcy? The answer lies in the deceptive accounting practices and outright fraud that Enron’s executives and auditors took part in. One factor is the massive amount of debt that Enron was hiding from its balance sheet. How does one go about hiding debt? “At the heart of Enron’s demise was the creation of partnerships with shell companies, many with names like Chewco and JEDI, inspired by Star Wars characters. These shell companies, run by Enron executives who profited richly from them, allowed Enron to keep hundreds of millions of dollars in debt off its books” (Nielsen, 2002, para. 4). At the same time, Enron’s board members, regulators, analysts, auditors, and even politicians looked the other way while Enron committed its fraud (Kadlec, 2001, para. 4). Enron’s auditing firm even went as far as to order their employees to shred all of the documents they used to do Enron’s audits! In the wake of Enron’s collapse, the general public demanded that the politicians step up, create, and enforce corporate law. This allowed for the creation of the Sarbanes-Oxley Act of 2002 which is still in effect today!</p>

<p> </p>

<p>Jaffe, Stephen. TIME. (2002). How Fastow Helped Enron fall. Retrieved from </p>

<p>Kadlec, Daniel. TIME. (2001). Power Failure. Retrieved from </p>

<p>Nielsen, James. TIME. (2002). Enron: Who’s Accountable? Retrieved from </p>
</div>
  
  


    </article>
  
  <div class="pagination">
    
      <a class="prev" href="/blog/page/6/">&larr; Older</a>
    
    <a href="/blog/archives">Blog Archives</a>
    
    <a class="next" href="/blog/page/4/">Newer &rarr;</a>
    
  </div>
</div>
<aside class="sidebar">
  
    <section>
	<script async src="http://pagead2.googlesyndication.com/pagead/js/adsbygoogle.js">
	</script>
	<ins class="adsbygoogle"
			 style="display:inline-block;width:250px;height:250px"
			 data-ad-client="ca-pub-9122341512723010"
			 data-ad-slot="3737400086"></ins>
	<script>
		(adsbygoogle = window.adsbygoogle || []).push({});
	</script>
</section>
<section>
  <h1>About Charles</h1>
	<img src="/wp-content/uploads/me-150x150.jpg" alt="Charles Hooper"/>
	<p>Charles is a hacker with a background in systems and operations engineering. He enjoys hacking on side projects, gardening, and home brewing.</p>
</section>
<section>
  <h1>Recent Posts</h1>
  <ul id="recent_posts">
    
      <li class="post">
        <a href="/blog/troubleshooting-elbs-with-elbping/">Troubleshooting ELBs with elbping</a>
      </li>
    
      <li class="post">
        <a href="/blog/my-def-con-21-experience/">My DEF CON 21 Experience</a>
      </li>
    
      <li class="post">
        <a href="/blog/why-i-moved-to-san-francisco/">Why I moved to San Francisco</a>
      </li>
    
      <li class="post">
        <a href="/blog/how-i-hacked-my-high-school/">How I Hacked My High School</a>
      </li>
    
      <li class="post">
        <a href="/blog/personal-kaizen-self-improvement/">My Personal Kaizen</a>
      </li>
    
  </ul>
</section>

<section>
	<script async src="http://pagead2.googlesyndication.com/pagead/js/adsbygoogle.js">
	</script>
	<ins class="adsbygoogle"
			 style="display:inline-block;width:250px;height:250px"
			 data-ad-client="ca-pub-9122341512723010"
			 data-ad-slot="3737400086"></ins>
	<script>
		(adsbygoogle = window.adsbygoogle || []).push({});
	</script>
</section>

  
</aside>

    </div>
  </div>
  <footer role="contentinfo"><p>
  Copyright &copy; 2013 - Charles Hooper -
  <span class="credit">Powered by <a href="http://octopress.org">Octopress</a></span>
</p>

</footer>
  

<script type="text/javascript">
      var disqus_shortname = 'charleshooper';
      
        
        var disqus_script = 'count.js';
      
    (function () {
      var dsq = document.createElement('script'); dsq.type = 'text/javascript'; dsq.async = true;
      dsq.src = 'http://' + disqus_shortname + '.disqus.com/' + disqus_script;
      (document.getElementsByTagName('head')[0] || document.getElementsByTagName('body')[0]).appendChild(dsq);
    }());
</script>







  <script type="text/javascript">
    (function(){
      var twitterWidgets = document.createElement('script');
      twitterWidgets.type = 'text/javascript';
      twitterWidgets.async = true;
      twitterWidgets.src = 'http://platform.twitter.com/widgets.js';
      document.getElementsByTagName('head')[0].appendChild(twitterWidgets);
    })();
  </script>





</body>
</html>
