
<!DOCTYPE html>
<!--[if IEMobile 7 ]><html class="no-js iem7"><![endif]-->
<!--[if lt IE 9]><html class="no-js lte-ie8"><![endif]-->
<!--[if (gt IE 8)|(gt IEMobile 7)|!(IEMobile)|!(IE)]><!--><html class="no-js" lang="en"><!--<![endif]-->
<head>
  <meta charset="utf-8">
  <title>Charles Hooper</title>
  <meta name="author" content="Charles Hooper">

  
  <meta name="description" content="32-bit limitations 32-bit MongoDB processes are limited to about 2.5 gb of data.  This has come as a surprise to a lot of people who are used to not &hellip;">
  

  <!-- http://t.co/dKP3o1e -->
  <meta name="HandheldFriendly" content="True">
  <meta name="MobileOptimized" content="320">
  <meta name="viewport" content="width=device-width, initial-scale=1">

  
  <link rel="canonical" href="http://www.charleshooper.net/blog/page/7">
  <link href="/favicon.png" rel="icon">
  <link href="/stylesheets/screen.css" media="screen, projection" rel="stylesheet" type="text/css">
  <link href="http://feeds.feedburner.com/subversity" rel="alternate" title="Charles Hooper" type="application/atom+xml">
  <script src="/javascripts/modernizr-2.0.js"></script>
  <script src="//ajax.googleapis.com/ajax/libs/jquery/1.9.1/jquery.min.js"></script>
  <script>!window.jQuery && document.write(unescape('%3Cscript src="./javascripts/lib/jquery.min.js"%3E%3C/script%3E'))</script>
  <script src="/javascripts/octopress.js" type="text/javascript"></script>
  <!--Fonts from Google"s Web font directory at http://google.com/webfonts -->
<link href="http://fonts.googleapis.com/css?family=PT+Serif:regular,italic,bold,bolditalic" rel="stylesheet" type="text/css">
<link href="http://fonts.googleapis.com/css?family=PT+Sans:regular,italic,bold,bolditalic" rel="stylesheet" type="text/css">

  
  <script type="text/javascript">
    var _gaq = _gaq || [];
    _gaq.push(['_setAccount', 'UA-12888528-1']);
    _gaq.push(['_trackPageview']);

    setTimeout("_gaq.push(['_trackEvent', '60_seconds', 'read'])", 60000);

    (function() {
      var ga = document.createElement('script'); ga.type = 'text/javascript'; ga.async = true;
      ga.src = ('https:' == document.location.protocol ? 'https://ssl' : 'http://www') + '.google-analytics.com/ga.js';
      var s = document.getElementsByTagName('script')[0]; s.parentNode.insertBefore(ga, s);
    })();
  </script>



</head>

<body   >
  <header role="banner"><hgroup>
  <h1><a href="/">Charles Hooper</a></h1>
  
    <h2>Thoughts and projects from a Hacker and Operations Engineer</h2>
  
</hgroup>

</header>
  <nav role="navigation"><ul class="subscription" data-subscription="rss">
  <li><a href="http://feeds.feedburner.com/subversity" rel="subscribe-rss" title="subscribe via RSS">RSS</a></li>
  
</ul>
  
<form action="http://google.com/search" method="get">
  <fieldset role="search">
    <input type="hidden" name="q" value="site:www.charleshooper.net" />
    <input class="search" type="text" name="q" results="0" placeholder="Search"/>
  </fieldset>
</form>
  
<ul class="main-navigation">
  <li><a href="/">Blog</a></li>
	<li><a href="/about/">About Charles</a></li>
	<li><a href="/projects/">Projects</a></li>
	<li><a href="/contact/">Contact</a></li>
  <li><a href="/blog/archives">Archives</a></li>
</ul>

</nav>
  <div id="main">
    <div id="content">
      <div class="blog-index">
  
  
  
    <article>
      
  <header>
    
      <h1 class="entry-title"><a href="/blog/mongodb-32-bit-limitations/">MongoDB &#8211; 32-bit Limitations</a></h1>
    
    
      <p class="meta">
        








  


<time datetime="2010-02-26T00:00:00-08:00" pubdate data-updated="true">Feb 26<span>th</span>, 2010</time>
        
      </p>
    
  </header>


  <div class="entry-content"><h1 id="section"></h1>

<blockquote>
  <h3 id="bit-limitations1"><a href="http://blog.mongodb.org/post/137788967/32-bit-limitations">32-bit limitations</a></h3>

  <p>32-bit MongoDB processes are limited to about 2.5 gb of data.  This has come as a surprise to a lot of people who are used to not having to worry about that.  The reason for this is that the MongoDB storage engine uses memory-mapped files for performance.</p>

  <p>By not supporting more than 2gb on 32-bit, we%u2019ve been able to keep our code much simpler and cleaner.  This greatly reduces the number of bugs, and reduces the time that we need to release a 1.0 product. The world is moving toward all 64-bit very quickly.  Right now there aren%u2019t too many people for whom 64-bit is a problem, and in the long term, we think this will be a non-issue.</p>

  <p><a href="http://blog.mongodb.org/post/137788967/32-bit-limitations">7 months ago</a>   via <a href="http://blog.mongodb.org/post/137788967/32-bit-limitations">blog.mongodb.org</a></p>

  <p>This is more recommended reading for those that are considering using MongoDB. For some, this is a deal-breaker. I don’t necessarily agree with this decision, but I do hope that 64bit support by hypervisors and VPS providers is more mature by the time Mongo matures.</p>
</blockquote>

</div>
  
  


    </article>
  
  
    <article>
      
  <header>
    
      <h1 class="entry-title"><a href="/blog/mongodb-what-about-durability/">MongoDB &#8211; What About Durability?</a></h1>
    
    
      <p class="meta">
        








  


<time datetime="2010-02-12T00:00:00-08:00" pubdate data-updated="true">Feb 12<span>th</span>, 2010</time>
        
      </p>
    
  </header>


  <div class="entry-content"><h1 id="section"></h1>

<blockquote>
  <h3 id="what-about-durability1"><a href="http://blog.mongodb.org/post/381927266/what-about-durability">What about Durability?</a></h3>

  <p>We get lots of questions about why MongoDB doesn’t have full single server durability, and there are many people that think this is a major problem.  We wanted to shed some light on why we haven’t done single server durability, what our suggestions are, and our future plans.</p>

  <p>To start, there are some very practical reasons why we think single server durability is overvalued.  First, there are many scenarios in which that server loses all its data no matter what.  If there is water damage, fire, some hardware problems, etc… no matter how durable the software is, data can be lost.  Yes – there are ways to mitigate some of these, but those add another layer of complexity, that has to be tested, proofed, and adds more variables which can fail.</p>

  <p>In the real world, traditional durability often isn’t even done correctly.  If you are using a DBMS that uses a transaction log for durability, you either have to turn off hardware buffering or have a battery backed RAID controller.  Without hardware buffering, transaction logs are very slow.  Battery backed raid controllers will work well, but you have to really have one.  With the move towards the cloud and outsourced hosting, custom hardware is not always an option.</p>

  <p>Requirements for web applications are also changing.  99.99% uptime is no longer the goal, people want 100% uptime as much as possible.  If you have durability through a transaction log, then you have to replay it to come back up.  If you have a master and slave in the same data center and you lose power, both will have to recover which could take 5-30 minutes.<a href="http://blog.mongodb.org/post/381927266/what-about-durability">1</a></p>

  <p>Another feature of new non-relational databases is horizontal scalability.  While MongoDB’s auto-sharding is still in Alpha, we still feel this is a core component. With horizontal scalability comes many servers.  If you have a 100 node cluster, worrying about every machine is a liability.  If a machine goes down in the middle of the night, you want the system to recover as fast as possible, without human intervention.  Given that, and that a high percentage of failures are hardware, the best thing is to just mark that server as inactive, and ignore it until someone can look at it easily (could be hours or days).</p>

  <p>Given all this, we’re not saying durability isn’t important, we just think that single server durability isn’t the best way to get true durability.  We think the right path to durability is replication (local and remote) and snapshotting.  That’s why we’ve spent so much time making replication fast and easy and work over wide area networks in MongoDB.</p>

  <p>We are currently planning many more enhancements to replication to make it better.</p>

  <ul>
    <li>psuedo real-time with optional blocking for writes until on multiple servers</li>
    <li>replica sets instead of replica pairs</li>
    <li>easier to create new slaves with large data sets</li>
  </ul>

  <p>Now – there are definitely some cases where single server durability is the best option.  It is on our road map, its just not on the short list right now.  We know what we want to do and how we want to do it, it’s just a matter of code :)</p>

  <p><a href="http://blog.mongodb.org/post/381927266/what-about-durability">1</a> Some databases such as CouchDB use an append only model that allows for instantaneous restarts. However, this type of design usually requires compaction routines to be run periodically, so can be costly in high update scenarios.</p>

  <p><a href="http://blog.mongodb.org/post/381927266/what-about-durability">1 day ago</a>   via <a href="http://blog.mongodb.org/post/381927266/what-about-durability">blog.mongodb.org</a></p>

  <p>This is very important to consider for anyone who is thinking about (or already is) using MongoDB.</p>
</blockquote>

</div>
  
  


    </article>
  
  
    <article>
      
  <header>
    
      <h1 class="entry-title"><a href="/blog/twitter-booksuggest/">Twitter BookSuggest</a></h1>
    
    
      <p class="meta">
        








  


<time datetime="2010-02-08T00:00:00-08:00" pubdate data-updated="true">Feb 8<span>th</span>, 2010</time>
        
      </p>
    
  </header>


  <div class="entry-content"><h1 id="section"></h1>

<p>Twitter BookSuggest is a web app that attempts to make book recommendations based on a person’s last 20 tweets. <strong>Clicking</strong> on a book cover will present you with a description of the book, as well as a clickable link to <a href="http://www.amazon.com/?tag=botter-20">Amazon.com</a> where you can purchase the book or add it to your wishlist. 
I’ve been working on this project for at the past couple of weeks, so please check it out. If you don’t use Twitter then just hang tight, I’ll be releasing a Facebook version shortly. </p>

</div>
  
  


    </article>
  
  
    <article>
      
  <header>
    
      <h1 class="entry-title"><a href="/blog/sudden-drop-of-tweets-after-the-superbowl-sb44/">Sudden Drop of Tweets After the Superbowl #SB44</a></h1>
    
    
      <p class="meta">
        








  


<time datetime="2010-02-08T00:00:00-08:00" pubdate data-updated="true">Feb 8<span>th</span>, 2010</time>
        
      </p>
    
  </header>


  <div class="entry-content"><h1 id="section"></h1>

<p><img src="http://www.charleshooper.net/wp-content/uploads/superbowl-300x164.png" alt="" /></p>

<p>Spritzer or “sample” or whatever it’s called. Entry-level streaming API access.</p>
</div>
  
  


    </article>
  
  
    <article>
      
  <header>
    
      <h1 class="entry-title"><a href="/blog/spike-in-tweets-as-soon-as-sb44-started/">Spike in Tweets as Soon as #SB44 Started</a></h1>
    
    
      <p class="meta">
        








  


<time datetime="2010-02-07T00:00:00-08:00" pubdate data-updated="true">Feb 7<span>th</span>, 2010</time>
        
      </p>
    
  </header>


  <div class="entry-content"><h1 id="section"></h1>

<p><img src="http://www.charleshooper.net/wp-content/uploads/pbr.plumata.net-booksuggest_ra-300x164.png" alt="" /></p>

</div>
  
  


    </article>
  
  
    <article>
      
  <header>
    
      <h1 class="entry-title"><a href="/blog/wtfbbq-spam-or-not/">WTFBBQ SPAM, or Not?</a></h1>
    
    
      <p class="meta">
        








  


<time datetime="2010-02-05T00:00:00-08:00" pubdate data-updated="true">Feb 5<span>th</span>, 2010</time>
        
      </p>
    
  </header>


  <div class="entry-content"><h1 id="section"></h1>

<p>Just received this fantastic recipe in my SPAM folder from an address I’ve never seen before. I’m assuming that this was just an attempt to verify the email address (no bounce = email is verified!) Or maybe it’s poison? 
&gt; Recipe for great BBQ Sauce: 
&gt; INGREDIENTS<br />
&gt; 1 quart apple cider vinegar<br />
&gt; 1 (20 ounce) bottle ketchup<br />
&gt; 1/4 cup paprika<br />
&gt; 1 pound dark brown sugar<br />
&gt; 1/4 cup salt<br />
&gt; 1 tablespoon black pepper<br />
&gt; 2 tablespoons red pepper flakes<br />
&gt; 1 tablespoon garlic powder<br />
&gt; 1/4 cup Worcestershire sauce<br />
&gt; 1/2 cup lemon juice 
&gt; DIRECTIONS<br />
&gt; In a large container, mix together the apple cider vinegar, ketchup,<br />
&gt; paprika, brown sugar, salt, pepper, red pepper flakes, garlic powder,<br />
&gt; Worcestershire sauce and lemon juice. Pour into an empty vinegar bottle,<br />
&gt; ketchup bottle or other container and store in the refrigerator for up to<br />
&gt; 1 month.</p>
</div>
  
  


    </article>
  
  
    <article>
      
  <header>
    
      <h1 class="entry-title"><a href="/blog/what-happens-when-you-dont-pay-your-employees-the-employee-employer-relationship/
/">What Happens When You Don&#8217;t Pay Your Employees: The Employee-Employer Relationship</a></h1>
    
    
      <p class="meta">
        








  


<time datetime="2010-02-02T00:00:00-08:00" pubdate data-updated="true">Feb 2<span>nd</span>, 2010</time>
        
      </p>
    
  </header>


  <div class="entry-content"><h1 id="section"></h1>

<p>The relationship between an employer and his or her employees isn’t special. It’s also very simple; <em>It’s based on money</em>. The employee works for the employer typically for 1-2 weeks at a time. Following this time period, the employer pays the employee and they’re even again. <em>You’re not friends</em>.</p>

<p>From a management perspective, it is true that you should pay attention to the human element of your employees, this falls under the behavioral approach to management. More specifically, employees that receive attention from their supervisors are, in general, more productive. This is known has the <strong>Hawthorne Effect</strong>. However, <em>this potential increase in productivity is moot if your employees aren’t getting paid</em>. Speaking from experience, here’s what will happen if you’re not paying your employees:</p>

<ol>
  <li>Your employees will show up for work late with increasing frequency</li>
  <li>Some days, they might not come in at all</li>
  <li>They’ll take long lunches</li>
  <li>They’ll leave early</li>
  <li>They’ll fuck off provided they actually do show up. Productivity will be down</li>
</ol>

<p>And here’s why: When I worked for a company that hadn’t paid anyone in two months, everyone gained a <strong>sense of entitlement</strong>. “They <em>owe</em>us. They’re lucky we’re even showing up for work at all!”</p>

<p>I still agree with that statement, they were lucky we even showed up at all. But here’s the problem: When you finally do pay your employees, you have to provide back pay, and you’re paying them their normal rate/salary. Not the “fuck-off and waltz in at noon” rate.</p>

<p>Here’s what’s worse: If an unpaid employee decides to leave or you decide to fire or lay them off, you are opening yourself up for a <strong>huge liability</strong>. In some states an employee is due their check the day that they leave (California, if given notice) or by the following payday (<a href="http://www.ctdol.state.ct.us/wgwkstnd/laws-regs/wglaws.htm">Connecticut Labor Law</a>.) <em>If you can’t pay your employee, they have the option of reporting you to the Department of Labor</em>. What happens then? You’re forced to pay the employee and fined additional monies. For what amounted to ~$200 unpaid wages, another former employer of mine would have been liable for an additional $500-$1000 in fines. In addition to the monetary penalties, you also risk getting audited. As a bookkeeper friend once told me: <em>You never want to open your books for anybody.</em>(Cool backstory, she had to open hers for a grand jury.)</p>

<p>If for some reason you really can’t pay your employees on time, you’re going to have to work something out with each of them on an individual basis. Make a *payment plan *with each them that you actually manage. Most importantly, <strong>GET YOUR AGREEMENT IN WRITING AND SIGNED BY BOTH PARTIES!</strong>Do not try to get the employee to waive amounts of their pay. In some states, this is illegal!</p>

<p>So, seriously, pay your employees or there may be serious consequences. If you can’t, work out a payment plan and get it in writing and signed.</p>

<p>P.S. – I’m not a lawyer, I’ve just been on the receiving end (or lack thereof) of not getting paid a couple of times and know the mentality, as well as my rights.</p>
</div>
  
  


    </article>
  
  
    <article>
      
  <header>
    
      <h1 class="entry-title"><a href="/blog/twitter-repeater-source-released/">Twitter-repeater Source Released</a></h1>
    
    
      <p class="meta">
        








  


<time datetime="2010-01-07T00:00:00-08:00" pubdate data-updated="true">Jan 7<span>th</span>, 2010</time>
        
      </p>
    
  </header>


  <div class="entry-content"><h1 id="section"></h1>

<p>Last night I finally released the <a href="http://code.google.com/p/twitter-repeater/">source to my twitter-repeater bot</a>. 
&gt; twitter-repeater is a bot that automatically retweets any tweets in which its name is “mentioned” in. In order for a tweet to be retweeted, the bot account must be following the original user who tweeted it, that user must not be on the ignore list, and the tweet must pass some basic quality tests. 
&gt; The idea was originally inspired by the <a href="http://twitter.com/sanmo">@SanMo</a> bot and was created so I could use something similar for <a href="http://twitter.com/NLCT">New London, CT (@NLCT)</a></p>

<p>The bot is released under the MIT license and makes use of the <a href="http://github.com/joshthecoder/tweepy">tweepy library.</a><br />
 </p>

</div>
  
  


    </article>
  
  
    <article>
      
  <header>
    
      <h1 class="entry-title"><a href="/blog/drinking-from-the-gardenhose-with-graphs/">Drinking From the Gardenhose, With Graphs!</a></h1>
    
    
      <p class="meta">
        








  


<time datetime="2009-12-23T00:00:00-08:00" pubdate data-updated="true">Dec 23<span>rd</span>, 2009</time>
        
      </p>
    
  </header>


  <div class="entry-content"><h1 id="section"></h1>

<p>My Tweet harvester stats look something like this. Base “sample” streaming level. Times are GMT or UTC.</p>

<p><img src="http://www.charleshooper.net/wp-content/uploads/bowserjr.plumata.net-harvester-300x171.png" alt="a" /><br />
<img src="http://www.charleshooper.net/wp-content/uploads/bowserjr.plumata.net-munin_rat-300x164.png" alt="b" /><br />
<img src="http://www.charleshooper.net/wp-content/uploads/magichat.plumata.net-mysql_slo-300x164.png" alt="c" /><br />
<img src="http://www.charleshooper.net/wp-content/uploads/magichat.plumata.net-mysql_que-300x207.png" alt="d" /><br />
<img src="http://www.charleshooper.net/wp-content/uploads/bowserjr.plumata.net-if_eth0-d-300x164.png" alt="e" /><br />
<img src="http://www.charleshooper.net/wp-content/uploads/bowserjr.plumata.net-munin_que-300x164.png" alt="f" /></p>

<p>Edit: I’m actually on spritzer, or whatever the base access level is. However, “drinking from the gardenhose” is a much cooler title.</p>

</div>
  
  


    </article>
  
  
    <article>
      
  <header>
    
      <h1 class="entry-title"><a href="/blog/drinking-from-the-gardenhose-cont/">Drinking From the Gardenhose, Cont.</a></h1>
    
    
      <p class="meta">
        








  


<time datetime="2009-12-16T00:00:00-08:00" pubdate data-updated="true">Dec 16<span>th</span>, 2009</time>
        
      </p>
    
  </header>


  <div class="entry-content"><h1 id="section"></h1>

<p>Previously I blogged about a <a href="http://subversity.net/drinking-from-the-gardenhose">storage/database bottleneck causing dropped connections while utilizing Twitter’s streaming API</a>. 
I’m happy to report that the switch from <em>sqlite to MySQL</em> resulted in an immediate increase in <strong>throughput</strong>. I went from processing <strong>~5 updates/second</strong> to processing just over <strong>11 updates/second</strong>, almost doubling my capacity.</p>

<p>I also saw great improvement in terms of <strong>CPU usage</strong> as well. Previously, I was pegging my CPU at <strong>100% usage</strong>. Since the switch to MySQL, which runs on another (similarly spec’d) host, I now use less than <strong>5% CPU</strong> on the stream listening/processing host and less than <strong>10% CPU</strong> on the MySQL host with the same dataset as before. I believe that parallelizing my code even further would allow me to take greater advantage of my resources and achieve higher throughput.</p>

<p>Resolving this issue has allowed me to turn my focus back on what I originally started this project for: Building a large enough corpus to do accurate <a href="http://en.wikipedia.org/wiki/Tf–idf">Tf-idf scoring</a>.</p>

</div>
  
  


    </article>
  
  <div class="pagination">
    
      <a class="prev" href="/blog/page/8/">&larr; Older</a>
    
    <a href="/blog/archives">Blog Archives</a>
    
    <a class="next" href="/blog/page/6/">Newer &rarr;</a>
    
  </div>
</div>
<aside class="sidebar">
  
    <section>
	<script async src="http://pagead2.googlesyndication.com/pagead/js/adsbygoogle.js">
	</script>
	<ins class="adsbygoogle"
			 style="display:inline-block;width:250px;height:250px"
			 data-ad-client="ca-pub-9122341512723010"
			 data-ad-slot="3737400086"></ins>
	<script>
		(adsbygoogle = window.adsbygoogle || []).push({});
	</script>
</section>
<section>
  <h1>About Charles</h1>
	<img src="/wp-content/uploads/me-150x150.jpg" alt="Charles Hooper"/>
	<p>Charles is a hacker with a background in systems and operations engineering. He enjoys hacking on side projects, gardening, and home brewing.</p>
</section>
<section>
  <h1>Recent Posts</h1>
  <ul id="recent_posts">
    
      <li class="post">
        <a href="/blog/my-def-con-21-experience/">My DEF CON 21 Experience</a>
      </li>
    
      <li class="post">
        <a href="/blog/why-i-moved-to-san-francisco/">Why I moved to San Francisco</a>
      </li>
    
      <li class="post">
        <a href="/blog/how-i-hacked-my-high-school/">How I Hacked My High School</a>
      </li>
    
      <li class="post">
        <a href="/blog/personal-kaizen-self-improvement/">My Personal Kaizen</a>
      </li>
    
      <li class="post">
        <a href="/blog/about-this-site-technical/">About this site (technical)</a>
      </li>
    
  </ul>
</section>

<section>
	<script async src="http://pagead2.googlesyndication.com/pagead/js/adsbygoogle.js">
	</script>
	<ins class="adsbygoogle"
			 style="display:inline-block;width:250px;height:250px"
			 data-ad-client="ca-pub-9122341512723010"
			 data-ad-slot="3737400086"></ins>
	<script>
		(adsbygoogle = window.adsbygoogle || []).push({});
	</script>
</section>

  
</aside>

    </div>
  </div>
  <footer role="contentinfo"><p>
  Copyright &copy; 2013 - Charles Hooper -
  <span class="credit">Powered by <a href="http://octopress.org">Octopress</a></span>
</p>

</footer>
  

<script type="text/javascript">
      var disqus_shortname = 'charleshooper';
      
        
        var disqus_script = 'count.js';
      
    (function () {
      var dsq = document.createElement('script'); dsq.type = 'text/javascript'; dsq.async = true;
      dsq.src = 'http://' + disqus_shortname + '.disqus.com/' + disqus_script;
      (document.getElementsByTagName('head')[0] || document.getElementsByTagName('body')[0]).appendChild(dsq);
    }());
</script>







  <script type="text/javascript">
    (function(){
      var twitterWidgets = document.createElement('script');
      twitterWidgets.type = 'text/javascript';
      twitterWidgets.async = true;
      twitterWidgets.src = 'http://platform.twitter.com/widgets.js';
      document.getElementsByTagName('head')[0].appendChild(twitterWidgets);
    })();
  </script>





</body>
</html>
